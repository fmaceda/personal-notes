{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d46a7c6",
   "metadata": {},
   "source": [
    "# Hash Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7069cc1",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Overview](#overview)\n",
    "2. [What is a Hash Table?](#what-is-a-hash-table)\n",
    "3. [Core Concepts](#core-concepts)\n",
    "   - [Hash Functions](#hash-functions)\n",
    "   - [Collision Handling](#collision-handling)\n",
    "   - [Load Factor](#load-factor)\n",
    "4. [Hash Table Operations](#hash-table-operations)\n",
    "5. [Collision Resolution Techniques](#collision-resolution-techniques)\n",
    "   - [Separate Chaining](#separate-chaining)\n",
    "   - [Open Addressing](#open-addressing)\n",
    "6. [Hash Functions](#hash-function-types)\n",
    "7. [Time and Space Complexity](#time-and-space-complexity)\n",
    "8. [Implementation Examples](#implementation-examples)\n",
    "9. [Common Applications](#common-applications)\n",
    "10. [Interview Problems](#interview-problems)\n",
    "11. [Hash Tables vs Other Data Structures](#hash-tables-vs-other-data-structures)\n",
    "12. [When to Use Hash Tables](#when-to-use-hash-tables)\n",
    "13. [Resources](#resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0357fc77",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "## Overview\n",
    "\n",
    "**Hash Tables** (also known as Hash Maps) are fundamental data structures that implement an associative array abstract data type, providing a mapping from keys to values. They use a hash function to compute an index into an array of buckets or slots, from which the desired value can be found, inserted, or deleted.\n",
    "\n",
    "**Key Characteristics:**\n",
    "- **Key-Value Storage**: Store data as key-value pairs for fast retrieval\n",
    "- **Hash Function**: Uses mathematical functions to map keys to array indices\n",
    "- **Average O(1) Operations**: Provides constant-time average performance for basic operations\n",
    "- **Dynamic Sizing**: Can grow and shrink based on the number of elements\n",
    "- **Collision Handling**: Implements strategies to handle when different keys hash to the same index\n",
    "\n",
    "**Fundamental Principles:**\n",
    "- **Hashing**: Transform keys into array indices using hash functions\n",
    "- **Collision Resolution**: Handle cases where multiple keys map to the same index\n",
    "- **Load Factor Management**: Balance between space usage and performance\n",
    "- **Uniform Distribution**: Ideal hash functions distribute keys evenly across the table\n",
    "\n",
    "Hash tables are among the most important and widely used data structures in computer science, forming the backbone of many algorithms, databases, caches, and programming language implementations. They provide an elegant solution to the fundamental problem of fast data retrieval and are essential for building efficient software systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b8d57e",
   "metadata": {},
   "source": [
    "<a id=\"what-is-a-hash-table\"></a>\n",
    "## What is a Hash Table?\n",
    "\n",
    "A **hash table** is a data structure that stores key-value pairs and uses a **hash function** to map keys to specific locations (indices) in an underlying array. This mapping allows for extremely fast average-case performance for insertion, deletion, and lookup operations.\n",
    "\n",
    "### Visual Representation\n",
    "```\n",
    "Hash Table Structure:\n",
    "    Key → Hash Function → Index → Value\n",
    "\n",
    "    \"apple\"  → hash(\"apple\") % 10 → 3 → \"fruit\"\n",
    "    \"dog\"    → hash(\"dog\") % 10   → 7 → \"animal\"\n",
    "    \"red\"    → hash(\"red\") % 10   → 1 → \"color\"\n",
    "\n",
    "Hash Table Array:\n",
    "Index:  0    1      2    3       4    5    6    7        8    9\n",
    "       [ ] [\"red\"] [ ] [\"apple\"] [ ] [ ] [ ] [\"dog\"]   [ ] [ ]\n",
    "           \"color\"     \"fruit\"                \"animal\"\n",
    "```\n",
    "\n",
    "### Key Components\n",
    "\n",
    "#### 1. **Hash Function**\n",
    "A mathematical function that converts keys into array indices\n",
    "```python\n",
    "def simple_hash(key, table_size):\n",
    "    return hash(key) % table_size\n",
    "```\n",
    "\n",
    "#### 2. **Buckets/Slots**\n",
    "Array positions where key-value pairs are stored\n",
    "```python\n",
    "# Array of size 10\n",
    "hash_table = [None] * 10\n",
    "```\n",
    "\n",
    "#### 3. **Key-Value Pairs**\n",
    "The actual data stored in the hash table\n",
    "```python\n",
    "# Examples of key-value pairs\n",
    "pairs = [\n",
    "    (\"name\", \"Alice\"),\n",
    "    (\"age\", 30),\n",
    "    (\"city\", \"New York\")\n",
    "]\n",
    "```\n",
    "\n",
    "### Key Terminology\n",
    "- **Hash Function**: Function that maps keys to indices\n",
    "- **Bucket**: A slot in the hash table array\n",
    "- **Hash Code**: The result of applying the hash function to a key\n",
    "- **Collision**: When two different keys hash to the same index\n",
    "- **Load Factor**: Ratio of stored elements to total table size\n",
    "- **Rehashing**: Process of resizing and rebuilding the hash table\n",
    "\n",
    "### Real-World Analogy\n",
    "Think of a hash table like a **library catalog system**:\n",
    "- **Books (Values)**: The actual items you want to find\n",
    "- **Call Numbers (Keys)**: Unique identifiers for each book\n",
    "- **Shelving System (Hash Function)**: Rules that determine which shelf a book goes on\n",
    "- **Shelves (Buckets)**: Physical locations where books are stored\n",
    "- **Catalog (Hash Table)**: The entire system that helps you quickly locate any book\n",
    "\n",
    "Just as a library's catalog system allows you to quickly find any book without searching every shelf, a hash table allows you to quickly find any value without checking every element in the data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9532ba6",
   "metadata": {},
   "source": [
    "<a id=\"core-concepts\"></a>\n",
    "## Core Concepts\n",
    "\n",
    "### Hash Functions\n",
    "\n",
    "A **hash function** is the heart of any hash table. It takes a key as input and produces an integer that serves as an index in the hash table array.\n",
    "\n",
    "#### Properties of Good Hash Functions\n",
    "\n",
    "1. **Deterministic**: Same input always produces the same output\n",
    "2. **Uniform Distribution**: Maps keys evenly across the hash table\n",
    "3. **Fast Computation**: Should be quick to calculate\n",
    "4. **Avalanche Effect**: Small changes in input cause large changes in output\n",
    "\n",
    "#### Example Hash Functions\n",
    "\n",
    "```python\n",
    "# Simple modular hash function\n",
    "def mod_hash(key, table_size):\n",
    "    return hash(key) % table_size\n",
    "\n",
    "# String hash function (polynomial rolling hash)\n",
    "def string_hash(s, table_size):\n",
    "    hash_val = 0\n",
    "    for char in s:\n",
    "        hash_val = (hash_val * 31 + ord(char)) % table_size\n",
    "    return hash_val\n",
    "\n",
    "# Multiplication method\n",
    "def mult_hash(key, table_size):\n",
    "    A = 0.6180339887  # Golden ratio - 1\n",
    "    return int(table_size * ((key * A) % 1))\n",
    "```\n",
    "\n",
    "### Collision Handling\n",
    "\n",
    "**Collisions** occur when two different keys hash to the same index. This is inevitable due to the pigeonhole principle - if you have more keys than array slots, some slots must contain multiple keys.\n",
    "\n",
    "#### Why Collisions Happen\n",
    "```python\n",
    "# Example of collision\n",
    "table_size = 10\n",
    "key1 = \"apple\"   # hash(\"apple\") % 10 might be 3\n",
    "key2 = \"grape\"   # hash(\"grape\") % 10 might also be 3\n",
    "# Both keys map to index 3 - collision!\n",
    "```\n",
    "\n",
    "#### Collision Resolution Preview\n",
    "1. **Separate Chaining**: Store multiple elements in each bucket using linked lists\n",
    "2. **Open Addressing**: Find alternative locations within the same array\n",
    "\n",
    "### Load Factor\n",
    "\n",
    "The **load factor** (α) is the ratio of the number of stored elements to the size of the hash table.\n",
    "\n",
    "```\n",
    "Load Factor (α) = Number of Elements / Table Size\n",
    "```\n",
    "\n",
    "#### Load Factor Impact\n",
    "```python\n",
    "# Examples of different load factors\n",
    "table_size = 10\n",
    "\n",
    "# Low load factor (α = 0.3)\n",
    "elements = 3\n",
    "load_factor = 3 / 10 = 0.3  # Less crowded, fewer collisions\n",
    "\n",
    "# High load factor (α = 0.9)\n",
    "elements = 9\n",
    "load_factor = 9 / 10 = 0.9  # More crowded, more collisions\n",
    "```\n",
    "\n",
    "#### Optimal Load Factor\n",
    "- **Separate Chaining**: α ≤ 1.0 (can exceed 1)\n",
    "- **Open Addressing**: α ≤ 0.7-0.8 (should stay below 1)\n",
    "\n",
    "### Dynamic Resizing\n",
    "\n",
    "When the load factor becomes too high, hash tables typically resize to maintain performance:\n",
    "\n",
    "```python\n",
    "def should_resize(num_elements, table_size, max_load_factor=0.75):\n",
    "    return (num_elements / table_size) > max_load_factor\n",
    "\n",
    "def resize_hash_table(old_table):\n",
    "    # Double the size\n",
    "    new_size = len(old_table) * 2\n",
    "    new_table = [[] for _ in range(new_size)]\n",
    "    \n",
    "    # Rehash all existing elements\n",
    "    for bucket in old_table:\n",
    "        for key, value in bucket:\n",
    "            new_index = hash(key) % new_size\n",
    "            new_table[new_index].append((key, value))\n",
    "    \n",
    "    return new_table\n",
    "```\n",
    "\n",
    "### Hash Table Performance Factors\n",
    "\n",
    "1. **Quality of Hash Function**: Better distribution = fewer collisions\n",
    "2. **Load Factor**: Lower load factor = better performance\n",
    "3. **Collision Resolution Method**: Different methods have different trade-offs\n",
    "4. **Data Patterns**: Some data distributions cause more collisions than others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6dabca",
   "metadata": {},
   "source": [
    "<a id=\"hash-table-operations\"></a>\n",
    "## Hash Table Operations\n",
    "\n",
    "### Core Operations\n",
    "\n",
    "#### 1. Insert (Put)\n",
    "**Operation**: Add a key-value pair to the hash table\n",
    "```python\n",
    "def insert(hash_table, key, value):\n",
    "    index = hash(key) % len(hash_table)\n",
    "    # Handle collision resolution here\n",
    "    hash_table[index] = (key, value)\n",
    "```\n",
    "**Time Complexity**: O(1) average, O(n) worst case\n",
    "\n",
    "#### 2. Search (Get)\n",
    "**Operation**: Retrieve the value associated with a key\n",
    "```python\n",
    "def search(hash_table, key):\n",
    "    index = hash(key) % len(hash_table)\n",
    "    # Handle collision resolution to find the correct key\n",
    "    if hash_table[index] and hash_table[index][0] == key:\n",
    "        return hash_table[index][1]\n",
    "    return None\n",
    "```\n",
    "**Time Complexity**: O(1) average, O(n) worst case\n",
    "\n",
    "#### 3. Delete (Remove)\n",
    "**Operation**: Remove a key-value pair from the hash table\n",
    "```python\n",
    "def delete(hash_table, key):\n",
    "    index = hash(key) % len(hash_table)\n",
    "    # Handle collision resolution to find and remove the correct key\n",
    "    if hash_table[index] and hash_table[index][0] == key:\n",
    "        hash_table[index] = None\n",
    "        return True\n",
    "    return False\n",
    "```\n",
    "**Time Complexity**: O(1) average, O(n) worst case\n",
    "\n",
    "### Basic Hash Table Implementation\n",
    "\n",
    "```python\n",
    "class SimpleHashTable:\n",
    "    def __init__(self, size=10):\n",
    "        self.size = size\n",
    "        self.table = [None] * size\n",
    "        self.num_elements = 0\n",
    "    \n",
    "    def _hash(self, key):\n",
    "        \"\"\"Simple hash function using built-in hash() and modulo\"\"\"\n",
    "        return hash(key) % self.size\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        \"\"\"Insert or update a key-value pair\"\"\"\n",
    "        index = self._hash(key)\n",
    "        \n",
    "        # Simple implementation - overwrites collisions\n",
    "        if self.table[index] is None:\n",
    "            self.num_elements += 1\n",
    "        \n",
    "        self.table[index] = (key, value)\n",
    "        \n",
    "        # Check if resize is needed\n",
    "        if self.num_elements / self.size > 0.7:\n",
    "            self._resize()\n",
    "    \n",
    "    def get(self, key):\n",
    "        \"\"\"Retrieve value for a given key\"\"\"\n",
    "        index = self._hash(key)\n",
    "        \n",
    "        if self.table[index] is not None:\n",
    "            stored_key, value = self.table[index]\n",
    "            if stored_key == key:\n",
    "                return value\n",
    "        \n",
    "        raise KeyError(f\"Key '{key}' not found\")\n",
    "    \n",
    "    def delete(self, key):\n",
    "        \"\"\"Remove a key-value pair\"\"\"\n",
    "        index = self._hash(key)\n",
    "        \n",
    "        if self.table[index] is not None:\n",
    "            stored_key, value = self.table[index]\n",
    "            if stored_key == key:\n",
    "                self.table[index] = None\n",
    "                self.num_elements -= 1\n",
    "                return value\n",
    "        \n",
    "        raise KeyError(f\"Key '{key}' not found\")\n",
    "    \n",
    "    def _resize(self):\n",
    "        \"\"\"Resize the hash table when load factor is too high\"\"\"\n",
    "        old_table = self.table\n",
    "        self.size *= 2\n",
    "        self.table = [None] * self.size\n",
    "        self.num_elements = 0\n",
    "        \n",
    "        # Rehash all existing elements\n",
    "        for item in old_table:\n",
    "            if item is not None:\n",
    "                key, value = item\n",
    "                self.put(key, value)\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the current state of the hash table\"\"\"\n",
    "        for i, item in enumerate(self.table):\n",
    "            if item is not None:\n",
    "                key, value = item\n",
    "                print(f\"Index {i}: {key} → {value}\")\n",
    "            else:\n",
    "                print(f\"Index {i}: Empty\")\n",
    "\n",
    "# Example usage\n",
    "ht = SimpleHashTable()\n",
    "ht.put(\"name\", \"Alice\")\n",
    "ht.put(\"age\", 30)\n",
    "ht.put(\"city\", \"New York\")\n",
    "\n",
    "print(f\"Name: {ht.get('name')}\")\n",
    "print(f\"Age: {ht.get('age')}\")\n",
    "\n",
    "ht.display()\n",
    "```\n",
    "\n",
    "### Advanced Operations\n",
    "\n",
    "#### 1. Contains (Has Key)\n",
    "```python\n",
    "def contains(self, key):\n",
    "    \"\"\"Check if a key exists in the hash table\"\"\"\n",
    "    try:\n",
    "        self.get(key)\n",
    "        return True\n",
    "    except KeyError:\n",
    "        return False\n",
    "```\n",
    "\n",
    "#### 2. Keys\n",
    "```python\n",
    "def keys(self):\n",
    "    \"\"\"Return all keys in the hash table\"\"\"\n",
    "    result = []\n",
    "    for item in self.table:\n",
    "        if item is not None:\n",
    "            key, value = item\n",
    "            result.append(key)\n",
    "    return result\n",
    "```\n",
    "\n",
    "#### 3. Values\n",
    "```python\n",
    "def values(self):\n",
    "    \"\"\"Return all values in the hash table\"\"\"\n",
    "    result = []\n",
    "    for item in self.table:\n",
    "        if item is not None:\n",
    "            key, value = item\n",
    "            result.append(value)\n",
    "    return result\n",
    "```\n",
    "\n",
    "#### 4. Items\n",
    "```python\n",
    "def items(self):\n",
    "    \"\"\"Return all key-value pairs\"\"\"\n",
    "    result = []\n",
    "    for item in self.table:\n",
    "        if item is not None:\n",
    "            result.append(item)\n",
    "    return result\n",
    "```\n",
    "\n",
    "### Operation Complexity Summary\n",
    "\n",
    "| Operation | Average Case | Worst Case | Best Case |\n",
    "|-----------|--------------|------------|-----------|\n",
    "| **Insert** | O(1) | O(n) | O(1) |\n",
    "| **Search** | O(1) | O(n) | O(1) |\n",
    "| **Delete** | O(1) | O(n) | O(1) |\n",
    "| **Space** | O(n) | O(n) | O(n) |\n",
    "\n",
    "**Note**: The worst-case scenario occurs when all keys hash to the same index, essentially creating a linear search through all elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec371f5",
   "metadata": {},
   "source": [
    "<a id=\"collision-resolution-techniques\"></a>\n",
    "## Collision Resolution Techniques\n",
    "\n",
    "When multiple keys hash to the same index, we need strategies to handle these collisions. There are two main approaches:\n",
    "\n",
    "### Separate Chaining\n",
    "\n",
    "**Separate Chaining** stores multiple elements in each bucket using additional data structures (typically linked lists).\n",
    "\n",
    "#### Visual Representation\n",
    "```\n",
    "Hash Table with Separate Chaining:\n",
    "Index:  0    1       2     3      4     5\n",
    "      [ ] → Node → [ ] → Node → Node → [ ]\n",
    "             ↓           ↓        ↓\n",
    "           \"dog\"      \"apple\"   \"grape\"\n",
    "          \"animal\"    \"fruit\"   \"fruit\"\n",
    "```\n",
    "\n",
    "#### Implementation\n",
    "```python\n",
    "class HashTableChaining:\n",
    "    def __init__(self, size=10):\n",
    "        self.size = size\n",
    "        self.table = [[] for _ in range(size)]  # List of lists\n",
    "        self.num_elements = 0\n",
    "    \n",
    "    def _hash(self, key):\n",
    "        return hash(key) % self.size\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        index = self._hash(key)\n",
    "        bucket = self.table[index]\n",
    "        \n",
    "        # Check if key already exists\n",
    "        for i, (k, v) in enumerate(bucket):\n",
    "            if k == key:\n",
    "                bucket[i] = (key, value)  # Update existing\n",
    "                return\n",
    "        \n",
    "        # Add new key-value pair\n",
    "        bucket.append((key, value))\n",
    "        self.num_elements += 1\n",
    "        \n",
    "        # Resize if load factor too high\n",
    "        if self.num_elements / self.size > 1.0:\n",
    "            self._resize()\n",
    "    \n",
    "    def get(self, key):\n",
    "        index = self._hash(key)\n",
    "        bucket = self.table[index]\n",
    "        \n",
    "        for k, v in bucket:\n",
    "            if k == key:\n",
    "                return v\n",
    "        \n",
    "        raise KeyError(f\"Key '{key}' not found\")\n",
    "    \n",
    "    def delete(self, key):\n",
    "        index = self._hash(key)\n",
    "        bucket = self.table[index]\n",
    "        \n",
    "        for i, (k, v) in enumerate(bucket):\n",
    "            if k == key:\n",
    "                del bucket[i]\n",
    "                self.num_elements -= 1\n",
    "                return v\n",
    "        \n",
    "        raise KeyError(f\"Key '{key}' not found\")\n",
    "    \n",
    "    def _resize(self):\n",
    "        old_table = self.table\n",
    "        self.size *= 2\n",
    "        self.table = [[] for _ in range(self.size)]\n",
    "        self.num_elements = 0\n",
    "        \n",
    "        for bucket in old_table:\n",
    "            for key, value in bucket:\n",
    "                self.put(key, value)\n",
    "\n",
    "# Example usage\n",
    "ht_chain = HashTableChaining(size=5)\n",
    "ht_chain.put(\"apple\", \"fruit\")\n",
    "ht_chain.put(\"dog\", \"animal\")\n",
    "ht_chain.put(\"red\", \"color\")\n",
    "ht_chain.put(\"grape\", \"fruit\")  # May collide with \"apple\"\n",
    "```\n",
    "\n",
    "#### Advantages of Separate Chaining\n",
    "- Simple to implement\n",
    "- Can handle high load factors (α > 1)\n",
    "- Easy deletion\n",
    "- Performance degrades gracefully\n",
    "\n",
    "#### Disadvantages of Separate Chaining\n",
    "- Extra memory overhead for pointers/references\n",
    "- Poor cache performance due to pointer chasing\n",
    "- Memory fragmentation\n",
    "\n",
    "### Open Addressing\n",
    "\n",
    "**Open Addressing** stores all elements in the hash table array itself. When a collision occurs, it finds another empty slot using a probing sequence.\n",
    "\n",
    "#### Linear Probing\n",
    "\n",
    "Find the next available slot by checking consecutive indices.\n",
    "\n",
    "```python\n",
    "class HashTableLinearProbing:\n",
    "    def __init__(self, size=10):\n",
    "        self.size = size\n",
    "        self.table = [None] * size\n",
    "        self.num_elements = 0\n",
    "    \n",
    "    def _hash(self, key):\n",
    "        return hash(key) % self.size\n",
    "    \n",
    "    def _probe(self, key):\n",
    "        \"\"\"Find the index for a key using linear probing\"\"\"\n",
    "        index = self._hash(key)\n",
    "        \n",
    "        while self.table[index] is not None:\n",
    "            stored_key, value = self.table[index]\n",
    "            if stored_key == key:\n",
    "                return index, True  # Found existing key\n",
    "            \n",
    "            index = (index + 1) % self.size  # Linear probing\n",
    "            \n",
    "            # Check if we've gone full circle\n",
    "            if index == self._hash(key):\n",
    "                raise Exception(\"Hash table is full\")\n",
    "        \n",
    "        return index, False  # Found empty slot\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        if self.num_elements >= self.size * 0.7:  # Resize before 70% full\n",
    "            self._resize()\n",
    "        \n",
    "        index, found = self._probe(key)\n",
    "        \n",
    "        if not found:\n",
    "            self.num_elements += 1\n",
    "        \n",
    "        self.table[index] = (key, value)\n",
    "    \n",
    "    def get(self, key):\n",
    "        index = self._hash(key)\n",
    "        \n",
    "        while self.table[index] is not None:\n",
    "            stored_key, value = self.table[index]\n",
    "            if stored_key == key:\n",
    "                return value\n",
    "            \n",
    "            index = (index + 1) % self.size\n",
    "            \n",
    "            if index == self._hash(key):\n",
    "                break  # We've searched the entire table\n",
    "        \n",
    "        raise KeyError(f\"Key '{key}' not found\")\n",
    "    \n",
    "    def delete(self, key):\n",
    "        index = self._hash(key)\n",
    "        \n",
    "        while self.table[index] is not None:\n",
    "            stored_key, value = self.table[index]\n",
    "            if stored_key == key:\n",
    "                self.table[index] = \"DELETED\"  # Tombstone\n",
    "                self.num_elements -= 1\n",
    "                return value\n",
    "            \n",
    "            index = (index + 1) % self.size\n",
    "            \n",
    "            if index == self._hash(key):\n",
    "                break\n",
    "        \n",
    "        raise KeyError(f\"Key '{key}' not found\")\n",
    "```\n",
    "\n",
    "#### Quadratic Probing\n",
    "\n",
    "Use quadratic function to find the next slot: `(hash(key) + i²) % size`\n",
    "\n",
    "```python\n",
    "def quadratic_probe(self, key):\n",
    "    index = self._hash(key)\n",
    "    i = 0\n",
    "    \n",
    "    while self.table[index] is not None:\n",
    "        stored_key, value = self.table[index]\n",
    "        if stored_key == key:\n",
    "            return index, True\n",
    "        \n",
    "        i += 1\n",
    "        index = (self._hash(key) + i * i) % self.size\n",
    "        \n",
    "        if i >= self.size:\n",
    "            raise Exception(\"Hash table is full\")\n",
    "    \n",
    "    return index, False\n",
    "```\n",
    "\n",
    "#### Double Hashing\n",
    "\n",
    "Use a second hash function to determine the step size.\n",
    "\n",
    "```python\n",
    "def double_hash_probe(self, key):\n",
    "    index = self._hash(key)\n",
    "    step = self._hash2(key)\n",
    "    \n",
    "    while self.table[index] is not None:\n",
    "        stored_key, value = self.table[index]\n",
    "        if stored_key == key:\n",
    "            return index, True\n",
    "        \n",
    "        index = (index + step) % self.size\n",
    "    \n",
    "    return index, False\n",
    "\n",
    "def _hash2(self, key):\n",
    "    \"\"\"Second hash function for double hashing\"\"\"\n",
    "    return 7 - (hash(key) % 7)  # Prime number different from table size\n",
    "```\n",
    "\n",
    "### Collision Resolution Comparison\n",
    "\n",
    "| Method | Pros | Cons | Best Use Case |\n",
    "|--------|------|------|---------------|\n",
    "| **Separate Chaining** | Simple, handles high load factors | Memory overhead, poor cache | General purpose |\n",
    "| **Linear Probing** | Good cache performance, no extra memory | Clustering issues | Cache-sensitive applications |\n",
    "| **Quadratic Probing** | Reduces clustering | More complex, may not find slots | Medium load factors |\n",
    "| **Double Hashing** | Excellent distribution | Complex, two hash functions | High-performance requirements |\n",
    "\n",
    "### Clustering in Open Addressing\n",
    "\n",
    "**Primary Clustering**: Long runs of occupied slots that increase search time\n",
    "```\n",
    "Linear Probing Clustering:\n",
    "[X][X][X][X][ ][ ][X][ ][ ][ ]\n",
    " ↑ Primary cluster\n",
    "```\n",
    "\n",
    "**Secondary Clustering**: Keys with the same hash value follow the same probe sequence\n",
    "```\n",
    "Quadratic Probing Secondary Clustering:\n",
    "Keys with hash(k) = 3 all probe: 3, 4, 7, 2, 9, 8, ...\n",
    "```\n",
    "\n",
    "**Solution**: Double hashing eliminates secondary clustering by using different step sizes for different keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a258def",
   "metadata": {},
   "source": [
    "<a id=\"hash-function-types\"></a>\n",
    "## Hash Functions\n",
    "\n",
    "The quality of a hash function directly impacts hash table performance. A good hash function distributes keys uniformly across the table, minimizing collisions.\n",
    "\n",
    "### Properties of Good Hash Functions\n",
    "\n",
    "1. **Deterministic**: Same input always produces same output\n",
    "2. **Uniform Distribution**: Keys spread evenly across hash table\n",
    "3. **Efficient**: Fast to compute\n",
    "4. **Avalanche Effect**: Small input changes cause large output changes\n",
    "\n",
    "### Common Hash Function Types\n",
    "\n",
    "#### 1. Division Method\n",
    "```python\n",
    "def division_hash(key, table_size):\n",
    "    \"\"\"Simple modulo hash function\"\"\"\n",
    "    return hash(key) % table_size\n",
    "\n",
    "# Choose table_size as a prime number for better distribution\n",
    "table_size = 101  # Prime number\n",
    "index = division_hash(\"hello\", table_size)\n",
    "```\n",
    "\n",
    "#### 2. Multiplication Method\n",
    "```python\n",
    "def multiplication_hash(key, table_size):\n",
    "    \"\"\"Multiplication method using golden ratio\"\"\"\n",
    "    A = 0.6180339887  # (√5 - 1) / 2 (golden ratio - 1)\n",
    "    hash_value = hash(key) * A\n",
    "    fractional_part = hash_value - int(hash_value)\n",
    "    return int(table_size * fractional_part)\n",
    "```\n",
    "\n",
    "#### 3. Universal Hashing\n",
    "```python\n",
    "import random\n",
    "\n",
    "class UniversalHashFunction:\n",
    "    def __init__(self, table_size):\n",
    "        self.table_size = table_size\n",
    "        self.p = 2**31 - 1  # Large prime number\n",
    "        self.a = random.randint(1, self.p - 1)\n",
    "        self.b = random.randint(0, self.p - 1)\n",
    "    \n",
    "    def hash(self, key):\n",
    "        \"\"\"Universal hash function: ((a*key + b) mod p) mod m\"\"\"\n",
    "        return ((self.a * hash(key) + self.b) % self.p) % self.table_size\n",
    "```\n",
    "\n",
    "#### 4. Cryptographic Hash Functions\n",
    "```python\n",
    "import hashlib\n",
    "\n",
    "def crypto_hash(key, table_size):\n",
    "    \"\"\"Using cryptographic hash function\"\"\"\n",
    "    # Convert key to string if necessary\n",
    "    key_str = str(key).encode('utf-8')\n",
    "    \n",
    "    # Use SHA-256\n",
    "    hash_object = hashlib.sha256(key_str)\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "    \n",
    "    # Convert to integer and mod by table size\n",
    "    hash_int = int(hash_hex, 16)\n",
    "    return hash_int % table_size\n",
    "```\n",
    "\n",
    "### String Hash Functions\n",
    "\n",
    "#### Polynomial Rolling Hash\n",
    "```python\n",
    "def polynomial_hash(s, table_size, base=31):\n",
    "    \"\"\"Polynomial rolling hash for strings\"\"\"\n",
    "    hash_value = 0\n",
    "    power = 1\n",
    "    \n",
    "    for char in s:\n",
    "        hash_value = (hash_value + ord(char) * power) % table_size\n",
    "        power = (power * base) % table_size\n",
    "    \n",
    "    return hash_value\n",
    "\n",
    "# Example\n",
    "text = \"hello\"\n",
    "hash_val = polynomial_hash(text, 1000)\n",
    "```\n",
    "\n",
    "#### FNV Hash (Fowler-Noll-Vo)\n",
    "```python\n",
    "def fnv_hash(data, table_size):\n",
    "    \"\"\"FNV-1a hash algorithm\"\"\"\n",
    "    FNV_OFFSET_BASIS = 2166136261\n",
    "    FNV_PRIME = 16777619\n",
    "    \n",
    "    hash_value = FNV_OFFSET_BASIS\n",
    "    \n",
    "    for byte in str(data).encode('utf-8'):\n",
    "        hash_value ^= byte\n",
    "        hash_value *= FNV_PRIME\n",
    "        hash_value &= 0xFFFFFFFF  # Keep it 32-bit\n",
    "    \n",
    "    return hash_value % table_size\n",
    "```\n",
    "\n",
    "### Hash Function Quality Testing\n",
    "\n",
    "#### Distribution Test\n",
    "```python\n",
    "def test_hash_distribution(hash_func, keys, table_size):\n",
    "    \"\"\"Test how evenly a hash function distributes keys\"\"\"\n",
    "    buckets = [0] * table_size\n",
    "    \n",
    "    for key in keys:\n",
    "        index = hash_func(key, table_size)\n",
    "        buckets[index] += 1\n",
    "    \n",
    "    # Calculate statistics\n",
    "    max_bucket = max(buckets)\n",
    "    min_bucket = min(buckets)\n",
    "    avg_bucket = sum(buckets) / len(buckets)\n",
    "    \n",
    "    print(f\"Max bucket size: {max_bucket}\")\n",
    "    print(f\"Min bucket size: {min_bucket}\")\n",
    "    print(f\"Average bucket size: {avg_bucket:.2f}\")\n",
    "    print(f\"Standard deviation: {(sum((b - avg_bucket)**2 for b in buckets) / len(buckets))**0.5:.2f}\")\n",
    "\n",
    "# Test with sample data\n",
    "test_keys = [f\"key_{i}\" for i in range(1000)]\n",
    "test_hash_distribution(division_hash, test_keys, 100)\n",
    "```\n",
    "\n",
    "#### Collision Analysis\n",
    "```python\n",
    "def analyze_collisions(hash_func, keys, table_size):\n",
    "    \"\"\"Analyze collision patterns\"\"\"\n",
    "    hash_counts = {}\n",
    "    \n",
    "    for key in keys:\n",
    "        hash_val = hash_func(key, table_size)\n",
    "        hash_counts[hash_val] = hash_counts.get(hash_val, 0) + 1\n",
    "    \n",
    "    collisions = sum(count - 1 for count in hash_counts.values() if count > 1)\n",
    "    total_slots_used = len(hash_counts)\n",
    "    \n",
    "    print(f\"Total keys: {len(keys)}\")\n",
    "    print(f\"Slots used: {total_slots_used}/{table_size}\")\n",
    "    print(f\"Total collisions: {collisions}\")\n",
    "    print(f\"Collision rate: {collisions/len(keys)*100:.2f}%\")\n",
    "    print(f\"Load factor: {len(keys)/table_size:.2f}\")\n",
    "\n",
    "# Analyze collision patterns\n",
    "analyze_collisions(division_hash, test_keys, 100)\n",
    "```\n",
    "\n",
    "### Choosing the Right Hash Function\n",
    "\n",
    "| Hash Function Type | Use Case | Pros | Cons |\n",
    "|-------------------|----------|------|------|\n",
    "| **Division Method** | General purpose | Simple, fast | Sensitive to table size |\n",
    "| **Multiplication Method** | Any table size | Table size flexibility | Slightly more complex |\n",
    "| **Universal Hashing** | Adversarial inputs | Theoretical guarantees | Randomization overhead |\n",
    "| **Cryptographic** | Security required | Excellent distribution | Slow computation |\n",
    "\n",
    "### Hash Function Implementation Example\n",
    "\n",
    "```python\n",
    "class HashFunction:\n",
    "    \"\"\"Configurable hash function class\"\"\"\n",
    "    \n",
    "    def __init__(self, method='division', table_size=101):\n",
    "        self.method = method\n",
    "        self.table_size = table_size\n",
    "        \n",
    "        if method == 'universal':\n",
    "            self.p = 2**31 - 1\n",
    "            import random\n",
    "            self.a = random.randint(1, self.p - 1)\n",
    "            self.b = random.randint(0, self.p - 1)\n",
    "    \n",
    "    def hash(self, key):\n",
    "        \"\"\"Apply the selected hash function\"\"\"\n",
    "        if self.method == 'division':\n",
    "            return hash(key) % self.table_size\n",
    "        \n",
    "        elif self.method == 'multiplication':\n",
    "            A = 0.6180339887\n",
    "            hash_value = hash(key) * A\n",
    "            return int(self.table_size * (hash_value - int(hash_value)))\n",
    "        \n",
    "        elif self.method == 'universal':\n",
    "            return ((self.a * hash(key) + self.b) % self.p) % self.table_size\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown hash method: {self.method}\")\n",
    "\n",
    "# Usage examples\n",
    "hash_func = HashFunction('division', 101)\n",
    "print(hash_func.hash(\"hello\"))\n",
    "\n",
    "hash_func = HashFunction('universal', 101)\n",
    "print(hash_func.hash(\"hello\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f863d1",
   "metadata": {},
   "source": [
    "<a id=\"time-and-space-complexity\"></a>\n",
    "## Time and Space Complexity\n",
    "\n",
    "Understanding the performance characteristics of hash tables is crucial for making informed decisions about when and how to use them.\n",
    "\n",
    "### Time Complexity Analysis\n",
    "\n",
    "#### Average Case Performance\n",
    "With a good hash function and reasonable load factor:\n",
    "\n",
    "| Operation | Average Time | Explanation |\n",
    "|-----------|--------------|-------------|\n",
    "| **Insert** | O(1) | Direct access to bucket + constant collision handling |\n",
    "| **Search** | O(1) | Direct hash computation + minimal collision resolution |\n",
    "| **Delete** | O(1) | Direct access + constant collision handling |\n",
    "\n",
    "#### Worst Case Performance\n",
    "When all keys hash to the same bucket:\n",
    "\n",
    "| Operation | Worst Time | Explanation |\n",
    "|-----------|------------|-------------|\n",
    "| **Insert** | O(n) | May need to traverse entire collision chain |\n",
    "| **Search** | O(n) | Linear search through all elements |\n",
    "| **Delete** | O(n) | Must find element in chain of all elements |\n",
    "\n",
    "#### Load Factor Impact\n",
    "\n",
    "```python\n",
    "def demonstrate_load_factor_impact():\n",
    "    \"\"\"Show how load factor affects performance\"\"\"\n",
    "    import time\n",
    "    \n",
    "    # Test different load factors\n",
    "    load_factors = [0.25, 0.5, 0.75, 0.9, 0.95]\n",
    "    \n",
    "    for lf in load_factors:\n",
    "        table_size = 1000\n",
    "        num_elements = int(table_size * lf)\n",
    "        \n",
    "        # Create hash table with specific load factor\n",
    "        ht = HashTableChaining(table_size)\n",
    "        \n",
    "        # Insert elements\n",
    "        start_time = time.time()\n",
    "        for i in range(num_elements):\n",
    "            ht.put(f\"key_{i}\", f\"value_{i}\")\n",
    "        insert_time = time.time() - start_time\n",
    "        \n",
    "        # Search elements\n",
    "        start_time = time.time()\n",
    "        for i in range(min(100, num_elements)):\n",
    "            ht.get(f\"key_{i}\")\n",
    "        search_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"Load Factor {lf}: Insert={insert_time:.4f}s, Search={search_time:.4f}s\")\n",
    "\n",
    "# Run demonstration\n",
    "demonstrate_load_factor_impact()\n",
    "```\n",
    "\n",
    "### Space Complexity\n",
    "\n",
    "#### Memory Usage Components\n",
    "\n",
    "1. **Table Array**: O(m) where m is table size\n",
    "2. **Stored Elements**: O(n) where n is number of elements\n",
    "3. **Collision Resolution Overhead**:\n",
    "   - **Separate Chaining**: O(n) for pointers/references\n",
    "   - **Open Addressing**: O(1) no extra overhead\n",
    "\n",
    "#### Total Space Complexity\n",
    "- **Overall**: O(n + m) = O(n) when m ≈ n\n",
    "- **Load Factor Impact**: Higher load factor = better space efficiency\n",
    "\n",
    "```python\n",
    "def analyze_space_complexity():\n",
    "    \"\"\"Analyze memory usage of different hash table implementations\"\"\"\n",
    "    import sys\n",
    "    \n",
    "    # Create hash tables with different implementations\n",
    "    sizes = [100, 1000, 10000]\n",
    "    \n",
    "    for size in sizes:\n",
    "        # Python dictionary (optimized hash table)\n",
    "        dict_table = {f\"key_{i}\": f\"value_{i}\" for i in range(size)}\n",
    "        dict_memory = sys.getsizeof(dict_table)\n",
    "        \n",
    "        # Our chaining implementation\n",
    "        chain_table = HashTableChaining(size)\n",
    "        for i in range(size):\n",
    "            chain_table.put(f\"key_{i}\", f\"value_{i}\")\n",
    "        \n",
    "        # Estimate memory for chaining (rough approximation)\n",
    "        chain_memory = (\n",
    "            sys.getsizeof(chain_table.table) +  # Main array\n",
    "            size * 64  # Estimated overhead per element\n",
    "        )\n",
    "        \n",
    "        print(f\"Size {size}:\")\n",
    "        print(f\"  Python dict: {dict_memory} bytes ({dict_memory/size:.1f} per element)\")\n",
    "        print(f\"  Chaining HT: {chain_memory} bytes ({chain_memory/size:.1f} per element)\")\n",
    "        print()\n",
    "\n",
    "analyze_space_complexity()\n",
    "```\n",
    "\n",
    "### Performance Comparison with Other Data Structures\n",
    "\n",
    "| Data Structure | Search | Insert | Delete | Space | Ordered? |\n",
    "|----------------|--------|--------|--------|-------|----------|\n",
    "| **Hash Table** | O(1)* | O(1)* | O(1)* | O(n) | No |\n",
    "| **Array (unsorted)** | O(n) | O(1) | O(n) | O(n) | No |\n",
    "| **Array (sorted)** | O(log n) | O(n) | O(n) | O(n) | Yes |\n",
    "| **Linked List** | O(n) | O(1) | O(n) | O(n) | No |\n",
    "| **Binary Search Tree** | O(log n) | O(log n) | O(log n) | O(n) | Yes |\n",
    "| **Red-Black Tree** | O(log n) | O(log n) | O(log n) | O(n) | Yes |\n",
    "\n",
    "*Average case performance\n",
    "\n",
    "### Factors Affecting Performance\n",
    "\n",
    "#### 1. Hash Function Quality\n",
    "```python\n",
    "def compare_hash_functions():\n",
    "    \"\"\"Compare performance of different hash functions\"\"\"\n",
    "    import time\n",
    "    \n",
    "    keys = [f\"test_key_{i}\" for i in range(1000)]\n",
    "    table_size = 100\n",
    "    \n",
    "    # Simple hash (poor quality)\n",
    "    def poor_hash(key, size):\n",
    "        return len(str(key)) % size\n",
    "    \n",
    "    # Good hash (built-in)\n",
    "    def good_hash(key, size):\n",
    "        return hash(key) % size\n",
    "    \n",
    "    for hash_func, name in [(poor_hash, \"Poor Hash\"), (good_hash, \"Good Hash\")]:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Count collisions\n",
    "        hash_counts = {}\n",
    "        for key in keys:\n",
    "            h = hash_func(key, table_size)\n",
    "            hash_counts[h] = hash_counts.get(h, 0) + 1\n",
    "        \n",
    "        collisions = sum(max(0, count - 1) for count in hash_counts.values())\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"{name}: {collisions} collisions, {end_time - start_time:.4f}s\")\n",
    "\n",
    "compare_hash_functions()\n",
    "```\n",
    "\n",
    "#### 2. Load Factor Management\n",
    "```python\n",
    "class AdaptiveHashTable:\n",
    "    \"\"\"Hash table that automatically resizes based on load factor\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_size=8, max_load_factor=0.75):\n",
    "        self.table = [[] for _ in range(initial_size)]\n",
    "        self.size = initial_size\n",
    "        self.num_elements = 0\n",
    "        self.max_load_factor = max_load_factor\n",
    "        self.resize_count = 0\n",
    "    \n",
    "    def _load_factor(self):\n",
    "        return self.num_elements / self.size\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        # Check if resize needed before insertion\n",
    "        if self._load_factor() >= self.max_load_factor:\n",
    "            self._resize()\n",
    "        \n",
    "        index = hash(key) % self.size\n",
    "        bucket = self.table[index]\n",
    "        \n",
    "        # Check if key exists\n",
    "        for i, (k, v) in enumerate(bucket):\n",
    "            if k == key:\n",
    "                bucket[i] = (key, value)\n",
    "                return\n",
    "        \n",
    "        # Add new element\n",
    "        bucket.append((key, value))\n",
    "        self.num_elements += 1\n",
    "    \n",
    "    def _resize(self):\n",
    "        old_table = self.table\n",
    "        old_size = self.size\n",
    "        \n",
    "        # Double the size\n",
    "        self.size *= 2\n",
    "        self.table = [[] for _ in range(self.size)]\n",
    "        self.num_elements = 0\n",
    "        self.resize_count += 1\n",
    "        \n",
    "        print(f\"Resizing from {old_size} to {self.size} (resize #{self.resize_count})\")\n",
    "        \n",
    "        # Rehash all elements\n",
    "        for bucket in old_table:\n",
    "            for key, value in bucket:\n",
    "                self.put(key, value)\n",
    "    \n",
    "    def get_stats(self):\n",
    "        return {\n",
    "            'size': self.size,\n",
    "            'elements': self.num_elements,\n",
    "            'load_factor': self._load_factor(),\n",
    "            'resize_count': self.resize_count\n",
    "        }\n",
    "\n",
    "# Demonstrate adaptive resizing\n",
    "adaptive_ht = AdaptiveHashTable()\n",
    "for i in range(50):\n",
    "    adaptive_ht.put(f\"key_{i}\", f\"value_{i}\")\n",
    "    if i % 10 == 0:\n",
    "        print(f\"After {i+1} insertions: {adaptive_ht.get_stats()}\")\n",
    "```\n",
    "\n",
    "### Best Practices for Performance\n",
    "\n",
    "1. **Choose appropriate initial size** (close to expected number of elements)\n",
    "2. **Use prime numbers for table sizes** (better distribution with division method)\n",
    "3. **Monitor and maintain optimal load factor** (0.5-0.75 for most applications)\n",
    "4. **Select hash function based on data characteristics**\n",
    "5. **Consider collision resolution method based on access patterns**\n",
    "6. **Implement dynamic resizing** for varying data sizes\n",
    "\n",
    "### Performance Monitoring\n",
    "\n",
    "```python\n",
    "class InstrumentedHashTable(HashTableChaining):\n",
    "    \"\"\"Hash table with performance monitoring\"\"\"\n",
    "    \n",
    "    def __init__(self, size=10):\n",
    "        super().__init__(size)\n",
    "        self.operation_counts = {'get': 0, 'put': 0, 'delete': 0}\n",
    "        self.collision_counts = {'get': 0, 'put': 0, 'delete': 0}\n",
    "        self.total_probe_distance = 0\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        self.operation_counts['put'] += 1\n",
    "        index = self._hash(key)\n",
    "        bucket_size = len(self.table[index])\n",
    "        \n",
    "        if bucket_size > 0:\n",
    "            self.collision_counts['put'] += 1\n",
    "        \n",
    "        super().put(key, value)\n",
    "    \n",
    "    def get(self, key):\n",
    "        self.operation_counts['get'] += 1\n",
    "        index = self._hash(key)\n",
    "        bucket_size = len(self.table[index])\n",
    "        \n",
    "        if bucket_size > 1:\n",
    "            self.collision_counts['get'] += 1\n",
    "        \n",
    "        return super().get(key)\n",
    "    \n",
    "    def get_performance_stats(self):\n",
    "        total_ops = sum(self.operation_counts.values())\n",
    "        total_collisions = sum(self.collision_counts.values())\n",
    "        \n",
    "        return {\n",
    "            'total_operations': total_ops,\n",
    "            'collision_rate': total_collisions / total_ops if total_ops > 0 else 0,\n",
    "            'current_load_factor': self.num_elements / self.size,\n",
    "            'operations_breakdown': self.operation_counts.copy(),\n",
    "            'collisions_breakdown': self.collision_counts.copy()\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "instrumented_ht = InstrumentedHashTable()\n",
    "for i in range(20):\n",
    "    instrumented_ht.put(f\"key_{i}\", f\"value_{i}\")\n",
    "\n",
    "for i in range(10):\n",
    "    instrumented_ht.get(f\"key_{i}\")\n",
    "\n",
    "print(\"Performance Statistics:\")\n",
    "stats = instrumented_ht.get_performance_stats()\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e984c562",
   "metadata": {},
   "source": [
    "<a id=\"implementation-examples\"></a>\n",
    "## Implementation Examples\n",
    "\n",
    "Let's implement several complete hash table variations to demonstrate different approaches and optimizations.\n",
    "\n",
    "### 1. Complete Hash Table with Linear Probing\n",
    "\n",
    "```python\n",
    "class LinearProbingHashTable:\n",
    "    \"\"\"Complete hash table implementation using linear probing\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_capacity=16, max_load_factor=0.75):\n",
    "        self.capacity = initial_capacity\n",
    "        self.size = 0\n",
    "        self.max_load_factor = max_load_factor\n",
    "        \n",
    "        # Use None to indicate empty slots, special DELETED marker for deleted slots\n",
    "        self.DELETED = object()  # Unique marker for deleted slots\n",
    "        self.keys = [None] * self.capacity\n",
    "        self.values = [None] * self.capacity\n",
    "    \n",
    "    def _hash(self, key):\n",
    "        \"\"\"Primary hash function\"\"\"\n",
    "        return hash(key) % self.capacity\n",
    "    \n",
    "    def _next_index(self, index):\n",
    "        \"\"\"Get next index for linear probing\"\"\"\n",
    "        return (index + 1) % self.capacity\n",
    "    \n",
    "    def _find_slot(self, key):\n",
    "        \"\"\"Find slot for key (for insertion or lookup)\"\"\"\n",
    "        index = self._hash(key)\n",
    "        original_index = index\n",
    "        \n",
    "        while True:\n",
    "            if self.keys[index] is None or self.keys[index] == self.DELETED:\n",
    "                # Empty or deleted slot found\n",
    "                return index, False\n",
    "            elif self.keys[index] == key:\n",
    "                # Key found\n",
    "                return index, True\n",
    "            \n",
    "            index = self._next_index(index)\n",
    "            \n",
    "            # Check if we've looped back to start (table full)\n",
    "            if index == original_index:\n",
    "                raise Exception(\"Hash table is full\")\n",
    "    \n",
    "    def _resize(self):\n",
    "        \"\"\"Resize and rehash the table when load factor is exceeded\"\"\"\n",
    "        old_keys = self.keys\n",
    "        old_values = self.values\n",
    "        old_capacity = self.capacity\n",
    "        \n",
    "        # Double the capacity\n",
    "        self.capacity *= 2\n",
    "        self.size = 0\n",
    "        self.keys = [None] * self.capacity\n",
    "        self.values = [None] * self.capacity\n",
    "        \n",
    "        # Rehash all non-deleted elements\n",
    "        for i in range(old_capacity):\n",
    "            if old_keys[i] is not None and old_keys[i] != self.DELETED:\n",
    "                self.put(old_keys[i], old_values[i])\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        \"\"\"Insert or update a key-value pair\"\"\"\n",
    "        # Check if resize is needed\n",
    "        if (self.size + 1) / self.capacity > self.max_load_factor:\n",
    "            self._resize()\n",
    "        \n",
    "        index, found = self._find_slot(key)\n",
    "        \n",
    "        if not found:\n",
    "            # New key\n",
    "            self.keys[index] = key\n",
    "            self.values[index] = value\n",
    "            self.size += 1\n",
    "        else:\n",
    "            # Update existing key\n",
    "            self.values[index] = value\n",
    "    \n",
    "    def get(self, key):\n",
    "        \"\"\"Retrieve value for a key\"\"\"\n",
    "        index, found = self._find_slot(key)\n",
    "        if found:\n",
    "            return self.values[index]\n",
    "        else:\n",
    "            raise KeyError(f\"Key '{key}' not found\")\n",
    "    \n",
    "    def delete(self, key):\n",
    "        \"\"\"Delete a key-value pair\"\"\"\n",
    "        index, found = self._find_slot(key)\n",
    "        if found:\n",
    "            self.keys[index] = self.DELETED\n",
    "            self.values[index] = None\n",
    "            self.size -= 1\n",
    "        else:\n",
    "            raise KeyError(f\"Key '{key}' not found\")\n",
    "    \n",
    "    def contains(self, key):\n",
    "        \"\"\"Check if key exists in table\"\"\"\n",
    "        try:\n",
    "            index, found = self._find_slot(key)\n",
    "            return found\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def load_factor(self):\n",
    "        \"\"\"Get current load factor\"\"\"\n",
    "        return self.size / self.capacity\n",
    "    \n",
    "    def display_table(self):\n",
    "        \"\"\"Display table contents for debugging\"\"\"\n",
    "        print(f\"Hash Table (size={self.size}, capacity={self.capacity}, load_factor={self.load_factor():.2f})\")\n",
    "        for i in range(self.capacity):\n",
    "            key = self.keys[i]\n",
    "            value = self.values[i]\n",
    "            \n",
    "            if key is None:\n",
    "                status = \"EMPTY\"\n",
    "            elif key == self.DELETED:\n",
    "                status = \"DELETED\"\n",
    "            else:\n",
    "                status = f\"{key} -> {value}\"\n",
    "            \n",
    "            print(f\"  [{i:2}]: {status}\")\n",
    "\n",
    "# Demo the linear probing hash table\n",
    "print(\"=== Linear Probing Hash Table Demo ===\")\n",
    "lp_table = LinearProbingHashTable(initial_capacity=8)\n",
    "\n",
    "# Insert some data\n",
    "data = [(\"apple\", 1), (\"banana\", 2), (\"cherry\", 3), (\"date\", 4), (\"elderberry\", 5)]\n",
    "for key, value in data:\n",
    "    lp_table.put(key, value)\n",
    "    print(f\"Inserted {key} -> {value}\")\n",
    "\n",
    "print(f\"\\nTable after insertions:\")\n",
    "lp_table.display_table()\n",
    "\n",
    "# Test operations\n",
    "print(f\"\\nOperations:\")\n",
    "print(f\"Get 'banana': {lp_table.get('banana')}\")\n",
    "print(f\"Contains 'cherry': {lp_table.contains('cherry')}\")\n",
    "print(f\"Contains 'grape': {lp_table.contains('grape')}\")\n",
    "\n",
    "# Delete an element\n",
    "lp_table.delete('cherry')\n",
    "print(f\"\\nAfter deleting 'cherry':\")\n",
    "lp_table.display_table()\n",
    "\n",
    "# Insert more to trigger resize\n",
    "lp_table.put('fig', 6)\n",
    "lp_table.put('grape', 7)\n",
    "lp_table.put('kiwi', 8)\n",
    "print(f\"\\nAfter adding more elements (should trigger resize):\")\n",
    "lp_table.display_table()\n",
    "```\n",
    "\n",
    "### 2. Robin Hood Hashing Implementation\n",
    "\n",
    "```python\n",
    "class RobinHoodHashTable:\n",
    "    \"\"\"\n",
    "    Robin Hood hashing: a variant of open addressing where we minimize\n",
    "    the maximum distance any element is from its ideal position\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, capacity=16):\n",
    "        self.capacity = capacity\n",
    "        self.size = 0\n",
    "        \n",
    "        # Store (key, value, distance) tuples\n",
    "        self.slots = [None] * self.capacity\n",
    "    \n",
    "    def _hash(self, key):\n",
    "        return hash(key) % self.capacity\n",
    "    \n",
    "    def _distance(self, index, ideal_index):\n",
    "        \"\"\"Calculate probe distance (handling wraparound)\"\"\"\n",
    "        if index >= ideal_index:\n",
    "            return index - ideal_index\n",
    "        else:\n",
    "            return (self.capacity - ideal_index) + index\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        \"\"\"Insert using Robin Hood hashing\"\"\"\n",
    "        index = self._hash(key)\n",
    "        distance = 0\n",
    "        inserting = (key, value, distance)\n",
    "        \n",
    "        while True:\n",
    "            if self.slots[index] is None:\n",
    "                # Found empty slot\n",
    "                self.slots[index] = inserting\n",
    "                self.size += 1\n",
    "                break\n",
    "            \n",
    "            existing_key, existing_value, existing_distance = self.slots[index]\n",
    "            \n",
    "            if existing_key == key:\n",
    "                # Update existing key\n",
    "                self.slots[index] = (key, value, existing_distance)\n",
    "                break\n",
    "            \n",
    "            # Robin Hood: if our distance is greater than existing element's distance,\n",
    "            # we \"rob\" this slot and continue inserting the displaced element\n",
    "            if distance > existing_distance:\n",
    "                self.slots[index] = inserting\n",
    "                inserting = (existing_key, existing_value, existing_distance)\n",
    "            \n",
    "            # Move to next slot\n",
    "            index = (index + 1) % self.capacity\n",
    "            distance += 1\n",
    "            \n",
    "            # Update distance for element we're trying to insert\n",
    "            if inserting == (key, value, distance - 1):\n",
    "                inserting = (key, value, distance)\n",
    "            else:\n",
    "                # We're now inserting a displaced element, update its distance\n",
    "                inserting = (inserting[0], inserting[1], distance)\n",
    "    \n",
    "    def get(self, key):\n",
    "        \"\"\"Retrieve value for key\"\"\"\n",
    "        index = self._hash(key)\n",
    "        distance = 0\n",
    "        \n",
    "        while self.slots[index] is not None:\n",
    "            existing_key, existing_value, existing_distance = self.slots[index]\n",
    "            \n",
    "            if existing_key == key:\n",
    "                return existing_value\n",
    "            \n",
    "            # If we've traveled further than this element did,\n",
    "            # the key definitely doesn't exist\n",
    "            if distance > existing_distance:\n",
    "                break\n",
    "            \n",
    "            index = (index + 1) % self.capacity\n",
    "            distance += 1\n",
    "        \n",
    "        raise KeyError(f\"Key '{key}' not found\")\n",
    "    \n",
    "    def display_table(self):\n",
    "        \"\"\"Display table with distances\"\"\"\n",
    "        print(f\"Robin Hood Hash Table (size={self.size}, capacity={self.capacity})\")\n",
    "        for i in range(self.capacity):\n",
    "            if self.slots[i] is None:\n",
    "                print(f\"  [{i:2}]: EMPTY\")\n",
    "            else:\n",
    "                key, value, distance = self.slots[i]\n",
    "                ideal_pos = self._hash(key)\n",
    "                print(f\"  [{i:2}]: {key} -> {value} (dist={distance}, ideal={ideal_pos})\")\n",
    "\n",
    "# Demo Robin Hood hashing\n",
    "print(\"\\n=== Robin Hood Hashing Demo ===\")\n",
    "rh_table = RobinHoodHashTable(capacity=8)\n",
    "\n",
    "# Insert data that will cause collisions\n",
    "keys = [\"a\", \"i\", \"q\", \"y\"]  # These might hash to similar positions\n",
    "for i, key in enumerate(keys):\n",
    "    rh_table.put(key, f\"value_{i}\")\n",
    "    print(f\"Inserted {key}\")\n",
    "\n",
    "rh_table.display_table()\n",
    "```\n",
    "\n",
    "### 3. Cuckoo Hashing Implementation\n",
    "\n",
    "```python\n",
    "class CuckooHashTable:\n",
    "    \"\"\"\n",
    "    Cuckoo hashing: uses two hash functions and two tables,\n",
    "    guarantees O(1) worst-case lookup time\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, capacity=8):\n",
    "        self.capacity = capacity\n",
    "        self.size = 0\n",
    "        self.max_iterations = capacity  # Prevent infinite loops\n",
    "        \n",
    "        # Two tables for cuckoo hashing\n",
    "        self.table1 = [None] * capacity\n",
    "        self.table2 = [None] * capacity\n",
    "    \n",
    "    def _hash1(self, key):\n",
    "        return hash(key) % self.capacity\n",
    "    \n",
    "    def _hash2(self, key):\n",
    "        # Use a different hash function\n",
    "        return (hash(key) * 31 + 17) % self.capacity\n",
    "    \n",
    "    def _insert_into_table(self, key, value, use_table1=True):\n",
    "        \"\"\"Insert into specified table, return displaced element if any\"\"\"\n",
    "        if use_table1:\n",
    "            index = self._hash1(key)\n",
    "            table = self.table1\n",
    "        else:\n",
    "            index = self._hash2(key)\n",
    "            table = self.table2\n",
    "        \n",
    "        displaced = table[index]\n",
    "        table[index] = (key, value)\n",
    "        return displaced\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        \"\"\"Insert using cuckoo hashing\"\"\"\n",
    "        # First check if key already exists\n",
    "        if self.contains(key):\n",
    "            # Update existing key\n",
    "            index1 = self._hash1(key)\n",
    "            index2 = self._hash2(key)\n",
    "            \n",
    "            if self.table1[index1] and self.table1[index1][0] == key:\n",
    "                self.table1[index1] = (key, value)\n",
    "            elif self.table2[index2] and self.table2[index2][0] == key:\n",
    "                self.table2[index2] = (key, value)\n",
    "            return\n",
    "        \n",
    "        # Try to insert in table1 first\n",
    "        current_key, current_value = key, value\n",
    "        use_table1 = True\n",
    "        \n",
    "        for iteration in range(self.max_iterations):\n",
    "            displaced = self._insert_into_table(current_key, current_value, use_table1)\n",
    "            \n",
    "            if displaced is None:\n",
    "                # Successfully inserted without displacement\n",
    "                self.size += 1\n",
    "                return\n",
    "            \n",
    "            # An element was displaced, try to place it in the other table\n",
    "            current_key, current_value = displaced\n",
    "            use_table1 = not use_table1\n",
    "        \n",
    "        # If we get here, we have a cycle - need to rehash\n",
    "        print(f\"Cycle detected, rehashing table...\")\n",
    "        self._rehash()\n",
    "        self.put(key, value)  # Try again with new hash functions\n",
    "    \n",
    "    def get(self, key):\n",
    "        \"\"\"Retrieve value for key - O(1) guaranteed\"\"\"\n",
    "        # Check table1\n",
    "        index1 = self._hash1(key)\n",
    "        if self.table1[index1] and self.table1[index1][0] == key:\n",
    "            return self.table1[index1][1]\n",
    "        \n",
    "        # Check table2\n",
    "        index2 = self._hash2(key)\n",
    "        if self.table2[index2] and self.table2[index2][0] == key:\n",
    "            return self.table2[index2][1]\n",
    "        \n",
    "        raise KeyError(f\"Key '{key}' not found\")\n",
    "    \n",
    "    def contains(self, key):\n",
    "        \"\"\"Check if key exists - O(1) guaranteed\"\"\"\n",
    "        try:\n",
    "            self.get(key)\n",
    "            return True\n",
    "        except KeyError:\n",
    "            return False\n",
    "    \n",
    "    def _rehash(self):\n",
    "        \"\"\"Rehash all elements with new capacity\"\"\"\n",
    "        old_table1 = self.table1\n",
    "        old_table2 = self.table2\n",
    "        old_capacity = self.capacity\n",
    "        \n",
    "        # Increase capacity and reset tables\n",
    "        self.capacity *= 2\n",
    "        self.table1 = [None] * self.capacity\n",
    "        self.table2 = [None] * self.capacity\n",
    "        self.size = 0\n",
    "        \n",
    "        # Reinsert all elements\n",
    "        for table in [old_table1, old_table2]:\n",
    "            for slot in table:\n",
    "                if slot is not None:\n",
    "                    key, value = slot\n",
    "                    self.put(key, value)\n",
    "    \n",
    "    def display_table(self):\n",
    "        \"\"\"Display both tables\"\"\"\n",
    "        print(f\"Cuckoo Hash Table (size={self.size}, capacity={self.capacity})\")\n",
    "        print(\"Table 1:\")\n",
    "        for i in range(self.capacity):\n",
    "            if self.table1[i] is None:\n",
    "                print(f\"  [{i:2}]: EMPTY\")\n",
    "            else:\n",
    "                key, value = self.table1[i]\n",
    "                print(f\"  [{i:2}]: {key} -> {value}\")\n",
    "        \n",
    "        print(\"Table 2:\")\n",
    "        for i in range(self.capacity):\n",
    "            if self.table2[i] is None:\n",
    "                print(f\"  [{i:2}]: EMPTY\")\n",
    "            else:\n",
    "                key, value = self.table2[i]\n",
    "                print(f\"  [{i:2}]: {key} -> {value}\")\n",
    "\n",
    "# Demo Cuckoo hashing\n",
    "print(\"\\n=== Cuckoo Hashing Demo ===\")\n",
    "cuckoo_table = CuckooHashTable(capacity=4)\n",
    "\n",
    "# Insert some data\n",
    "test_data = [(\"x\", 1), (\"y\", 2), (\"z\", 3), (\"w\", 4)]\n",
    "for key, value in test_data:\n",
    "    cuckoo_table.put(key, value)\n",
    "    print(f\"Inserted {key} -> {value}\")\n",
    "\n",
    "cuckoo_table.display_table()\n",
    "\n",
    "# Test lookups\n",
    "print(f\"\\nLookups:\")\n",
    "for key, _ in test_data:\n",
    "    print(f\"get('{key}') = {cuckoo_table.get(key)}\")\n",
    "```\n",
    "\n",
    "### 4. Consistent Hashing Implementation\n",
    "\n",
    "```python\n",
    "import bisect\n",
    "from typing import Any, List, Optional\n",
    "\n",
    "class ConsistentHashRing:\n",
    "    \"\"\"\n",
    "    Consistent hashing implementation for distributed systems.\n",
    "    Useful for load balancing and distributed caches.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, nodes: List[str] = None, replicas: int = 150):\n",
    "        \"\"\"\n",
    "        Initialize consistent hash ring\n",
    "        \n",
    "        Args:\n",
    "            nodes: List of node identifiers\n",
    "            replicas: Number of virtual nodes per physical node (for better distribution)\n",
    "        \"\"\"\n",
    "        self.replicas = replicas\n",
    "        self.ring = {}  # Maps hash values to nodes\n",
    "        self.sorted_hashes = []  # Sorted list of hash values\n",
    "        \n",
    "        if nodes:\n",
    "            for node in nodes:\n",
    "                self.add_node(node)\n",
    "    \n",
    "    def _hash(self, key: str) -> int:\n",
    "        \"\"\"Hash function for the ring\"\"\"\n",
    "        return hash(key) & 0x7FFFFFFF  # Ensure positive integer\n",
    "    \n",
    "    def add_node(self, node: str):\n",
    "        \"\"\"Add a node to the hash ring\"\"\"\n",
    "        for i in range(self.replicas):\n",
    "            virtual_node = f\"{node}:{i}\"\n",
    "            hash_value = self._hash(virtual_node)\n",
    "            \n",
    "            self.ring[hash_value] = node\n",
    "            bisect.insort(self.sorted_hashes, hash_value)\n",
    "        \n",
    "        print(f\"Added node '{node}' with {self.replicas} virtual nodes\")\n",
    "    \n",
    "    def remove_node(self, node: str):\n",
    "        \"\"\"Remove a node from the hash ring\"\"\"\n",
    "        for i in range(self.replicas):\n",
    "            virtual_node = f\"{node}:{i}\"\n",
    "            hash_value = self._hash(virtual_node)\n",
    "            \n",
    "            if hash_value in self.ring:\n",
    "                del self.ring[hash_value]\n",
    "                self.sorted_hashes.remove(hash_value)\n",
    "        \n",
    "        print(f\"Removed node '{node}'\")\n",
    "    \n",
    "    def get_node(self, key: str) -> Optional[str]:\n",
    "        \"\"\"Get the node responsible for a given key\"\"\"\n",
    "        if not self.ring:\n",
    "            return None\n",
    "        \n",
    "        hash_value = self._hash(key)\n",
    "        \n",
    "        # Find the first node with hash >= key's hash\n",
    "        index = bisect.bisect_right(self.sorted_hashes, hash_value)\n",
    "        \n",
    "        # If we're past the end, wrap around to the beginning\n",
    "        if index == len(self.sorted_hashes):\n",
    "            index = 0\n",
    "        \n",
    "        return self.ring[self.sorted_hashes[index]]\n",
    "    \n",
    "    def get_nodes(self, key: str, count: int) -> List[str]:\n",
    "        \"\"\"Get multiple nodes for a key (for replication)\"\"\"\n",
    "        if not self.ring or count <= 0:\n",
    "            return []\n",
    "        \n",
    "        hash_value = self._hash(key)\n",
    "        nodes = []\n",
    "        seen_nodes = set()\n",
    "        \n",
    "        # Start from the first node >= key's hash\n",
    "        start_index = bisect.bisect_right(self.sorted_hashes, hash_value)\n",
    "        \n",
    "        # Collect unique nodes\n",
    "        for i in range(len(self.sorted_hashes)):\n",
    "            index = (start_index + i) % len(self.sorted_hashes)\n",
    "            node = self.ring[self.sorted_hashes[index]]\n",
    "            \n",
    "            if node not in seen_nodes:\n",
    "                nodes.append(node)\n",
    "                seen_nodes.add(node)\n",
    "                \n",
    "                if len(nodes) == count:\n",
    "                    break\n",
    "        \n",
    "        return nodes\n",
    "    \n",
    "    def get_distribution(self, keys: List[str]) -> dict:\n",
    "        \"\"\"Analyze key distribution across nodes\"\"\"\n",
    "        distribution = {}\n",
    "        \n",
    "        for key in keys:\n",
    "            node = self.get_node(key)\n",
    "            distribution[node] = distribution.get(node, 0) + 1\n",
    "        \n",
    "        return distribution\n",
    "    \n",
    "    def display_ring(self, max_entries: int = 20):\n",
    "        \"\"\"Display the hash ring structure\"\"\"\n",
    "        print(f\"Consistent Hash Ring ({len(self.sorted_hashes)} virtual nodes)\")\n",
    "        \n",
    "        displayed = 0\n",
    "        for hash_value in self.sorted_hashes:\n",
    "            if displayed >= max_entries:\n",
    "                print(f\"  ... ({len(self.sorted_hashes) - displayed} more entries)\")\n",
    "                break\n",
    "            \n",
    "            node = self.ring[hash_value]\n",
    "            print(f\"  {hash_value:10} -> {node}\")\n",
    "            displayed += 1\n",
    "\n",
    "# Demo consistent hashing\n",
    "print(\"\\n=== Consistent Hashing Demo ===\")\n",
    "\n",
    "# Create hash ring with some nodes\n",
    "nodes = [\"server1\", \"server2\", \"server3\"]\n",
    "hash_ring = ConsistentHashRing(nodes, replicas=50)\n",
    "\n",
    "# Test key distribution\n",
    "test_keys = [f\"key_{i}\" for i in range(100)]\n",
    "distribution = hash_ring.get_distribution(test_keys)\n",
    "\n",
    "print(f\"\\nKey distribution across {len(nodes)} nodes:\")\n",
    "for node, count in distribution.items():\n",
    "    percentage = (count / len(test_keys)) * 100\n",
    "    print(f\"  {node}: {count} keys ({percentage:.1f}%)\")\n",
    "\n",
    "# Add a new node and see how keys redistribute\n",
    "print(f\"\\nAdding new node 'server4'...\")\n",
    "hash_ring.add_node(\"server4\")\n",
    "\n",
    "new_distribution = hash_ring.get_distribution(test_keys)\n",
    "print(f\"\\nNew distribution across {len(hash_ring.get_distribution(['dummy']).keys())} nodes:\")\n",
    "for node, count in new_distribution.items():\n",
    "    percentage = (count / len(test_keys)) * 100\n",
    "    print(f\"  {node}: {count} keys ({percentage:.1f}%)\")\n",
    "\n",
    "# Show how many keys moved\n",
    "moved_keys = 0\n",
    "for key in test_keys:\n",
    "    old_node = None\n",
    "    for node, count in distribution.items():\n",
    "        if hash_ring.get_node(key) != node:\n",
    "            continue\n",
    "        old_node = node\n",
    "        break\n",
    "    \n",
    "    new_node = hash_ring.get_node(key)\n",
    "    if old_node != new_node:\n",
    "        moved_keys += 1\n",
    "\n",
    "print(f\"\\nKeys that moved after adding server4: {moved_keys}/{len(test_keys)} ({(moved_keys/len(test_keys)*100):.1f}%)\")\n",
    "\n",
    "# Test replication\n",
    "print(f\"\\nReplication example (3 replicas for 'important_key'):\")\n",
    "replicas = hash_ring.get_nodes('important_key', 3)\n",
    "print(f\"  Nodes: {replicas}\")\n",
    "```\n",
    "\n",
    "These implementations demonstrate:\n",
    "\n",
    "1. **Linear Probing**: Simple open addressing with automatic resizing\n",
    "2. **Robin Hood Hashing**: Minimizes maximum probe distance for more predictable performance\n",
    "3. **Cuckoo Hashing**: Guarantees O(1) worst-case lookup time using two tables\n",
    "4. **Consistent Hashing**: For distributed systems where nodes can be added/removed dynamically\n",
    "\n",
    "Each implementation shows different trade-offs between complexity, performance guarantees, and memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d94f8",
   "metadata": {},
   "source": [
    "<a id=\"common-applications\"></a>\n",
    "## Common Applications\n",
    "\n",
    "Hash tables are versatile data structures with numerous practical applications across computer science and software development.\n",
    "\n",
    "### 1. Database Indexing\n",
    "\n",
    "Hash indexes provide O(1) average-case lookup for exact-match queries:\n",
    "\n",
    "```python\n",
    "class DatabaseHashIndex:\n",
    "    \"\"\"Simplified database hash index implementation\"\"\"\n",
    "    \n",
    "    def __init__(self, bucket_size=1000):\n",
    "        self.index = [[] for _ in range(bucket_size)]\n",
    "        self.bucket_size = bucket_size\n",
    "    \n",
    "    def _hash(self, key):\n",
    "        return hash(key) % self.bucket_size\n",
    "    \n",
    "    def insert(self, key, record_id):\n",
    "        \"\"\"Insert a key-record_id pair into the index\"\"\"\n",
    "        bucket_index = self._hash(key)\n",
    "        bucket = self.index[bucket_index]\n",
    "        \n",
    "        # Check if key already exists\n",
    "        for i, (existing_key, record_ids) in enumerate(bucket):\n",
    "            if existing_key == key:\n",
    "                record_ids.add(record_id)\n",
    "                return\n",
    "        \n",
    "        # Add new entry\n",
    "        bucket.append((key, {record_id}))\n",
    "    \n",
    "    def lookup(self, key):\n",
    "        \"\"\"Find all record IDs for a given key\"\"\"\n",
    "        bucket_index = self._hash(key)\n",
    "        bucket = self.index[bucket_index]\n",
    "        \n",
    "        for existing_key, record_ids in bucket:\n",
    "            if existing_key == key:\n",
    "                return record_ids\n",
    "        \n",
    "        return set()  # Key not found\n",
    "    \n",
    "    def delete(self, key, record_id=None):\n",
    "        \"\"\"Delete key or specific record_id for key\"\"\"\n",
    "        bucket_index = self._hash(key)\n",
    "        bucket = self.index[bucket_index]\n",
    "        \n",
    "        for i, (existing_key, record_ids) in enumerate(bucket):\n",
    "            if existing_key == key:\n",
    "                if record_id is None:\n",
    "                    # Delete entire key\n",
    "                    del bucket[i]\n",
    "                else:\n",
    "                    # Delete specific record_id\n",
    "                    record_ids.discard(record_id)\n",
    "                    if not record_ids:  # Remove key if no records left\n",
    "                        del bucket[i]\n",
    "                return True\n",
    "        \n",
    "        return False  # Key not found\n",
    "\n",
    "# Example usage\n",
    "db_index = DatabaseHashIndex()\n",
    "\n",
    "# Simulate database records\n",
    "records = [\n",
    "    (\"john_smith\", 1001),\n",
    "    (\"jane_doe\", 1002),\n",
    "    (\"john_smith\", 1003),  # Same name, different record\n",
    "    (\"bob_wilson\", 1004),\n",
    "]\n",
    "\n",
    "print(\"=== Database Hash Index Demo ===\")\n",
    "for name, record_id in records:\n",
    "    db_index.insert(name, record_id)\n",
    "    print(f\"Indexed: {name} -> record {record_id}\")\n",
    "\n",
    "# Query the index\n",
    "print(f\"\\nLookup 'john_smith': {db_index.lookup('john_smith')}\")\n",
    "print(f\"Lookup 'jane_doe': {db_index.lookup('jane_doe')}\")\n",
    "print(f\"Lookup 'unknown': {db_index.lookup('unknown')}\")\n",
    "```\n",
    "\n",
    "### 2. Caching Systems\n",
    "\n",
    "Hash tables are fundamental to implementing caches like LRU (Least Recently Used) caches:\n",
    "\n",
    "```python\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "\n",
    "class LRUCache:\n",
    "    \"\"\"LRU Cache implementation using hash table + doubly linked list\"\"\"\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.cache = OrderedDict()  # Python's OrderedDict uses hash table internally\n",
    "        self.access_times = {}\n",
    "        self.hit_count = 0\n",
    "        self.miss_count = 0\n",
    "    \n",
    "    def get(self, key):\n",
    "        \"\"\"Get value from cache\"\"\"\n",
    "        if key in self.cache:\n",
    "            # Move to end (most recently used)\n",
    "            self.cache.move_to_end(key)\n",
    "            self.access_times[key] = time.time()\n",
    "            self.hit_count += 1\n",
    "            return self.cache[key]\n",
    "        else:\n",
    "            self.miss_count += 1\n",
    "            return None\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        \"\"\"Put key-value pair in cache\"\"\"\n",
    "        if key in self.cache:\n",
    "            # Update existing key\n",
    "            self.cache[key] = value\n",
    "            self.cache.move_to_end(key)\n",
    "        else:\n",
    "            # Add new key\n",
    "            if len(self.cache) >= self.capacity:\n",
    "                # Remove least recently used item\n",
    "                oldest_key = next(iter(self.cache))\n",
    "                del self.cache[oldest_key]\n",
    "                del self.access_times[oldest_key]\n",
    "            \n",
    "            self.cache[key] = value\n",
    "        \n",
    "        self.access_times[key] = time.time()\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get cache statistics\"\"\"\n",
    "        total_requests = self.hit_count + self.miss_count\n",
    "        hit_rate = (self.hit_count / total_requests * 100) if total_requests > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'size': len(self.cache),\n",
    "            'capacity': self.capacity,\n",
    "            'hits': self.hit_count,\n",
    "            'misses': self.miss_count,\n",
    "            'hit_rate': f\"{hit_rate:.1f}%\"\n",
    "        }\n",
    "    \n",
    "    def display_cache(self):\n",
    "        \"\"\"Display current cache contents\"\"\"\n",
    "        print(f\"LRU Cache Contents (oldest -> newest):\")\n",
    "        for key, value in self.cache.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "# Demo LRU Cache\n",
    "print(\"\\n=== LRU Cache Demo ===\")\n",
    "cache = LRUCache(capacity=3)\n",
    "\n",
    "# Simulate cache operations\n",
    "operations = [\n",
    "    ('put', 'a', 1),\n",
    "    ('put', 'b', 2),\n",
    "    ('put', 'c', 3),\n",
    "    ('get', 'a', None),  # 'a' becomes most recent\n",
    "    ('put', 'd', 4),     # Should evict 'b' (least recent)\n",
    "    ('get', 'b', None),  # Should miss\n",
    "    ('get', 'c', None),  # Should hit\n",
    "    ('put', 'e', 5),     # Should evict 'd'\n",
    "]\n",
    "\n",
    "for op_type, key, value in operations:\n",
    "    if op_type == 'put':\n",
    "        cache.put(key, value)\n",
    "        print(f\"PUT {key}={value}\")\n",
    "    else:\n",
    "        result = cache.get(key)\n",
    "        print(f\"GET {key} -> {result}\")\n",
    "    \n",
    "    cache.display_cache()\n",
    "    print(f\"Stats: {cache.get_stats()}\")\n",
    "    print()\n",
    "```\n",
    "\n",
    "### 3. Symbol Tables in Compilers\n",
    "\n",
    "Hash tables are used to store variable names, function names, and their associated information:\n",
    "\n",
    "```python\n",
    "class SymbolTable:\n",
    "    \"\"\"Symbol table for compiler/interpreter\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scopes = [{}]  # Stack of scopes (each scope is a hash table)\n",
    "        self.current_scope = 0\n",
    "    \n",
    "    def enter_scope(self):\n",
    "        \"\"\"Enter a new scope (e.g., function or block)\"\"\"\n",
    "        self.scopes.append({})\n",
    "        self.current_scope += 1\n",
    "        print(f\"Entered scope level {self.current_scope}\")\n",
    "    \n",
    "    def exit_scope(self):\n",
    "        \"\"\"Exit current scope\"\"\"\n",
    "        if self.current_scope > 0:\n",
    "            removed_scope = self.scopes.pop()\n",
    "            self.current_scope -= 1\n",
    "            print(f\"Exited scope level {self.current_scope + 1}, removed {len(removed_scope)} symbols\")\n",
    "        else:\n",
    "            print(\"Cannot exit global scope\")\n",
    "    \n",
    "    def declare(self, name, symbol_type, value=None, line_number=None):\n",
    "        \"\"\"Declare a symbol in current scope\"\"\"\n",
    "        current_scope_table = self.scopes[self.current_scope]\n",
    "        \n",
    "        if name in current_scope_table:\n",
    "            print(f\"Warning: Symbol '{name}' already declared in current scope\")\n",
    "        \n",
    "        current_scope_table[name] = {\n",
    "            'type': symbol_type,\n",
    "            'value': value,\n",
    "            'line_declared': line_number,\n",
    "            'scope_level': self.current_scope\n",
    "        }\n",
    "        \n",
    "        print(f\"Declared {symbol_type} '{name}' in scope {self.current_scope}\")\n",
    "    \n",
    "    def lookup(self, name):\n",
    "        \"\"\"Look up symbol starting from current scope up to global\"\"\"\n",
    "        # Search from current scope up to global scope\n",
    "        for scope_level in range(self.current_scope, -1, -1):\n",
    "            if name in self.scopes[scope_level]:\n",
    "                symbol_info = self.scopes[scope_level][name].copy()\n",
    "                symbol_info['found_at_scope'] = scope_level\n",
    "                return symbol_info\n",
    "        \n",
    "        return None  # Symbol not found\n",
    "    \n",
    "    def update(self, name, value):\n",
    "        \"\"\"Update symbol value (find in nearest scope)\"\"\"\n",
    "        for scope_level in range(self.current_scope, -1, -1):\n",
    "            if name in self.scopes[scope_level]:\n",
    "                self.scopes[scope_level][name]['value'] = value\n",
    "                print(f\"Updated '{name}' = {value} in scope {scope_level}\")\n",
    "                return True\n",
    "        \n",
    "        print(f\"Error: Symbol '{name}' not declared\")\n",
    "        return False\n",
    "    \n",
    "    def display_all_scopes(self):\n",
    "        \"\"\"Display all scopes and their symbols\"\"\"\n",
    "        print(f\"\\nSymbol Table (current scope: {self.current_scope}):\")\n",
    "        for level, scope in enumerate(self.scopes):\n",
    "            print(f\"  Scope {level}:\")\n",
    "            if not scope:\n",
    "                print(f\"    (empty)\")\n",
    "            else:\n",
    "                for name, info in scope.items():\n",
    "                    print(f\"    {name}: {info['type']} = {info['value']}\")\n",
    "\n",
    "# Demo symbol table\n",
    "print(\"\\n=== Symbol Table Demo ===\")\n",
    "symbols = SymbolTable()\n",
    "\n",
    "# Global scope\n",
    "symbols.declare('PI', 'constant', 3.14159, line_number=1)\n",
    "symbols.declare('counter', 'variable', 0, line_number=2)\n",
    "\n",
    "# Function scope\n",
    "symbols.enter_scope()\n",
    "symbols.declare('x', 'parameter', None, line_number=5)\n",
    "symbols.declare('y', 'parameter', None, line_number=5)\n",
    "symbols.declare('result', 'variable', None, line_number=6)\n",
    "\n",
    "# Block scope within function\n",
    "symbols.enter_scope()\n",
    "symbols.declare('temp', 'variable', None, line_number=8)\n",
    "symbols.declare('counter', 'variable', 10, line_number=9)  # Shadows global counter\n",
    "\n",
    "symbols.display_all_scopes()\n",
    "\n",
    "# Test lookups\n",
    "print(f\"\\nLookups:\")\n",
    "print(f\"lookup('PI'): {symbols.lookup('PI')}\")\n",
    "print(f\"lookup('x'): {symbols.lookup('x')}\")\n",
    "print(f\"lookup('counter'): {symbols.lookup('counter')}\")  # Should find local counter\n",
    "print(f\"lookup('undefined'): {symbols.lookup('undefined')}\")\n",
    "\n",
    "# Test updates\n",
    "symbols.update('counter', 15)  # Updates local counter\n",
    "symbols.update('PI', 3.14)     # Updates global PI\n",
    "\n",
    "symbols.exit_scope()  # Exit block scope\n",
    "print(f\"\\nAfter exiting block scope:\")\n",
    "print(f\"lookup('counter'): {symbols.lookup('counter')}\")  # Should find global counter now\n",
    "print(f\"lookup('temp'): {symbols.lookup('temp')}\")        # Should be None\n",
    "\n",
    "symbols.exit_scope()  # Exit function scope\n",
    "symbols.display_all_scopes()\n",
    "```\n",
    "\n",
    "### 4. Set Operations and Membership Testing\n",
    "\n",
    "Hash tables provide efficient set operations:\n",
    "\n",
    "```python\n",
    "class HashSet:\n",
    "    \"\"\"Set implementation using hash table\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_capacity=16):\n",
    "        self.capacity = initial_capacity\n",
    "        self.size = 0\n",
    "        self.buckets = [[] for _ in range(initial_capacity)]\n",
    "        self.load_factor_threshold = 0.75\n",
    "    \n",
    "    def _hash(self, item):\n",
    "        return hash(item) % self.capacity\n",
    "    \n",
    "    def _resize(self):\n",
    "        \"\"\"Resize when load factor exceeds threshold\"\"\"\n",
    "        old_buckets = self.buckets\n",
    "        self.capacity *= 2\n",
    "        self.size = 0\n",
    "        self.buckets = [[] for _ in range(self.capacity)]\n",
    "        \n",
    "        # Rehash all items\n",
    "        for bucket in old_buckets:\n",
    "            for item in bucket:\n",
    "                self.add(item)\n",
    "    \n",
    "    def add(self, item):\n",
    "        \"\"\"Add item to set\"\"\"\n",
    "        # Check load factor\n",
    "        if self.size / self.capacity > self.load_factor_threshold:\n",
    "            self._resize()\n",
    "        \n",
    "        bucket_index = self._hash(item)\n",
    "        bucket = self.buckets[bucket_index]\n",
    "        \n",
    "        if item not in bucket:\n",
    "            bucket.append(item)\n",
    "            self.size += 1\n",
    "    \n",
    "    def remove(self, item):\n",
    "        \"\"\"Remove item from set\"\"\"\n",
    "        bucket_index = self._hash(item)\n",
    "        bucket = self.buckets[bucket_index]\n",
    "        \n",
    "        if item in bucket:\n",
    "            bucket.remove(item)\n",
    "            self.size -= 1\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def contains(self, item):\n",
    "        \"\"\"Check if item is in set\"\"\"\n",
    "        bucket_index = self._hash(item)\n",
    "        bucket = self.buckets[bucket_index]\n",
    "        return item in bucket\n",
    "    \n",
    "    def union(self, other_set):\n",
    "        \"\"\"Return union of two sets\"\"\"\n",
    "        result = HashSet()\n",
    "        \n",
    "        # Add all items from self\n",
    "        for bucket in self.buckets:\n",
    "            for item in bucket:\n",
    "                result.add(item)\n",
    "        \n",
    "        # Add all items from other_set\n",
    "        for bucket in other_set.buckets:\n",
    "            for item in bucket:\n",
    "                result.add(item)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def intersection(self, other_set):\n",
    "        \"\"\"Return intersection of two sets\"\"\"\n",
    "        result = HashSet()\n",
    "        \n",
    "        # Check items in smaller set against larger set\n",
    "        smaller, larger = (self, other_set) if self.size <= other_set.size else (other_set, self)\n",
    "        \n",
    "        for bucket in smaller.buckets:\n",
    "            for item in bucket:\n",
    "                if larger.contains(item):\n",
    "                    result.add(item)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def difference(self, other_set):\n",
    "        \"\"\"Return items in self but not in other_set\"\"\"\n",
    "        result = HashSet()\n",
    "        \n",
    "        for bucket in self.buckets:\n",
    "            for item in bucket:\n",
    "                if not other_set.contains(item):\n",
    "                    result.add(item)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def to_list(self):\n",
    "        \"\"\"Convert set to list\"\"\"\n",
    "        items = []\n",
    "        for bucket in self.buckets:\n",
    "            items.extend(bucket)\n",
    "        return items\n",
    "\n",
    "# Demo set operations\n",
    "print(\"\\n=== Hash Set Demo ===\")\n",
    "\n",
    "set1 = HashSet()\n",
    "set2 = HashSet()\n",
    "\n",
    "# Add items to sets\n",
    "for item in [1, 2, 3, 4, 5]:\n",
    "    set1.add(item)\n",
    "\n",
    "for item in [4, 5, 6, 7, 8]:\n",
    "    set2.add(item)\n",
    "\n",
    "print(f\"Set 1: {sorted(set1.to_list())}\")\n",
    "print(f\"Set 2: {sorted(set2.to_list())}\")\n",
    "\n",
    "# Set operations\n",
    "union_set = set1.union(set2)\n",
    "intersection_set = set1.intersection(set2)\n",
    "difference_set = set1.difference(set2)\n",
    "\n",
    "print(f\"Union: {sorted(union_set.to_list())}\")\n",
    "print(f\"Intersection: {sorted(intersection_set.to_list())}\")\n",
    "print(f\"Difference (Set1 - Set2): {sorted(difference_set.to_list())}\")\n",
    "\n",
    "# Membership testing\n",
    "print(f\"\\nMembership testing:\")\n",
    "for item in [1, 5, 10]:\n",
    "    print(f\"  {item} in Set1: {set1.contains(item)}\")\n",
    "    print(f\"  {item} in Set2: {set2.contains(item)}\")\n",
    "```\n",
    "\n",
    "### 5. Frequency Counting and Analytics\n",
    "\n",
    "Hash tables are perfect for counting occurrences and statistical analysis:\n",
    "\n",
    "```python\n",
    "class FrequencyAnalyzer:\n",
    "    \"\"\"Frequency analysis using hash tables\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.word_count = {}\n",
    "        self.char_count = {}\n",
    "        self.total_words = 0\n",
    "        self.total_chars = 0\n",
    "    \n",
    "    def analyze_text(self, text):\n",
    "        \"\"\"Analyze frequency of words and characters in text\"\"\"\n",
    "        # Clean and split text\n",
    "        words = text.lower().replace('.', '').replace(',', '').replace('!', '').replace('?', '').split()\n",
    "        \n",
    "        # Count words\n",
    "        for word in words:\n",
    "            self.word_count[word] = self.word_count.get(word, 0) + 1\n",
    "            self.total_words += 1\n",
    "        \n",
    "        # Count characters (excluding spaces and punctuation)\n",
    "        for char in text.lower():\n",
    "            if char.isalpha():\n",
    "                self.char_count[char] = self.char_count.get(char, 0) + 1\n",
    "                self.total_chars += 1\n",
    "    \n",
    "    def get_most_frequent_words(self, n=10):\n",
    "        \"\"\"Get n most frequent words\"\"\"\n",
    "        # Sort by frequency (descending)\n",
    "        sorted_words = sorted(self.word_count.items(), key=lambda x: x[1], reverse=True)\n",
    "        return sorted_words[:n]\n",
    "    \n",
    "    def get_most_frequent_chars(self, n=10):\n",
    "        \"\"\"Get n most frequent characters\"\"\"\n",
    "        sorted_chars = sorted(self.char_count.items(), key=lambda x: x[1], reverse=True)\n",
    "        return sorted_chars[:n]\n",
    "    \n",
    "    def get_word_frequency(self, word):\n",
    "        \"\"\"Get frequency of specific word\"\"\"\n",
    "        count = self.word_count.get(word.lower(), 0)\n",
    "        percentage = (count / self.total_words * 100) if self.total_words > 0 else 0\n",
    "        return count, percentage\n",
    "    \n",
    "    def get_statistics(self):\n",
    "        \"\"\"Get overall statistics\"\"\"\n",
    "        unique_words = len(self.word_count)\n",
    "        unique_chars = len(self.char_count)\n",
    "        \n",
    "        return {\n",
    "            'total_words': self.total_words,\n",
    "            'unique_words': unique_words,\n",
    "            'total_chars': self.total_chars,\n",
    "            'unique_chars': unique_chars,\n",
    "            'vocabulary_richness': unique_words / self.total_words if self.total_words > 0 else 0\n",
    "        }\n",
    "\n",
    "# Demo frequency analysis\n",
    "print(\"\\n=== Frequency Analysis Demo ===\")\n",
    "\n",
    "sample_text = \"\"\"\n",
    "The quick brown fox jumps over the lazy dog. The dog was really lazy,\n",
    "but the fox was very quick and brown. Quick brown foxes are amazing!\n",
    "\"\"\"\n",
    "\n",
    "analyzer = FrequencyAnalyzer()\n",
    "analyzer.analyze_text(sample_text)\n",
    "\n",
    "# Display statistics\n",
    "stats = analyzer.get_statistics()\n",
    "print(f\"Text Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Most frequent words\n",
    "print(f\"\\nMost frequent words:\")\n",
    "for word, count in analyzer.get_most_frequent_words(5):\n",
    "    percentage = (count / analyzer.total_words) * 100\n",
    "    print(f\"  '{word}': {count} times ({percentage:.1f}%)\")\n",
    "\n",
    "# Most frequent characters\n",
    "print(f\"\\nMost frequent characters:\")\n",
    "for char, count in analyzer.get_most_frequent_chars(10):\n",
    "    percentage = (count / analyzer.total_chars) * 100\n",
    "    print(f\"  '{char}': {count} times ({percentage:.1f}%)\")\n",
    "\n",
    "# Specific word analysis\n",
    "test_words = ['the', 'quick', 'lazy', 'amazing']\n",
    "print(f\"\\nSpecific word frequencies:\")\n",
    "for word in test_words:\n",
    "    count, percentage = analyzer.get_word_frequency(word)\n",
    "    print(f\"  '{word}': {count} times ({percentage:.1f}%)\")\n",
    "```\n",
    "\n",
    "### 6. Graph Algorithms (Adjacency Lists)\n",
    "\n",
    "Hash tables are commonly used to represent graphs:\n",
    "\n",
    "```python\n",
    "class Graph:\n",
    "    \"\"\"Graph representation using hash table for adjacency lists\"\"\"\n",
    "    \n",
    "    def __init__(self, directed=False):\n",
    "        self.adjacency_list = {}  # Hash table: vertex -> list of neighbors\n",
    "        self.directed = directed\n",
    "        self.vertex_count = 0\n",
    "        self.edge_count = 0\n",
    "    \n",
    "    def add_vertex(self, vertex):\n",
    "        \"\"\"Add a vertex to the graph\"\"\"\n",
    "        if vertex not in self.adjacency_list:\n",
    "            self.adjacency_list[vertex] = []\n",
    "            self.vertex_count += 1\n",
    "            print(f\"Added vertex: {vertex}\")\n",
    "    \n",
    "    def add_edge(self, v1, v2, weight=1):\n",
    "        \"\"\"Add an edge between two vertices\"\"\"\n",
    "        # Ensure vertices exist\n",
    "        self.add_vertex(v1)\n",
    "        self.add_vertex(v2)\n",
    "        \n",
    "        # Add edge v1 -> v2\n",
    "        if v2 not in self.adjacency_list[v1]:\n",
    "            self.adjacency_list[v1].append(v2)\n",
    "            self.edge_count += 1\n",
    "            \n",
    "            # If undirected, add reverse edge\n",
    "            if not self.directed and v1 not in self.adjacency_list[v2]:\n",
    "                self.adjacency_list[v2].append(v1)\n",
    "            \n",
    "            print(f\"Added edge: {v1} -> {v2}\")\n",
    "    \n",
    "    def get_neighbors(self, vertex):\n",
    "        \"\"\"Get all neighbors of a vertex\"\"\"\n",
    "        return self.adjacency_list.get(vertex, [])\n",
    "    \n",
    "    def has_edge(self, v1, v2):\n",
    "        \"\"\"Check if edge exists between two vertices\"\"\"\n",
    "        return v2 in self.adjacency_list.get(v1, [])\n",
    "    \n",
    "    def bfs(self, start_vertex):\n",
    "        \"\"\"Breadth-First Search traversal\"\"\"\n",
    "        if start_vertex not in self.adjacency_list:\n",
    "            return []\n",
    "        \n",
    "        visited = set()\n",
    "        queue = [start_vertex]\n",
    "        result = []\n",
    "        \n",
    "        while queue:\n",
    "            vertex = queue.pop(0)\n",
    "            \n",
    "            if vertex not in visited:\n",
    "                visited.add(vertex)\n",
    "                result.append(vertex)\n",
    "                \n",
    "                # Add unvisited neighbors to queue\n",
    "                for neighbor in self.adjacency_list[vertex]:\n",
    "                    if neighbor not in visited:\n",
    "                        queue.append(neighbor)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def dfs(self, start_vertex, visited=None):\n",
    "        \"\"\"Depth-First Search traversal\"\"\"\n",
    "        if visited is None:\n",
    "            visited = set()\n",
    "        \n",
    "        if start_vertex not in self.adjacency_list or start_vertex in visited:\n",
    "            return []\n",
    "        \n",
    "        visited.add(start_vertex)\n",
    "        result = [start_vertex]\n",
    "        \n",
    "        for neighbor in self.adjacency_list[start_vertex]:\n",
    "            result.extend(self.dfs(neighbor, visited))\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def find_path(self, start, end, path=None):\n",
    "        \"\"\"Find a path between two vertices using DFS\"\"\"\n",
    "        if path is None:\n",
    "            path = []\n",
    "        \n",
    "        path = path + [start]\n",
    "        \n",
    "        if start == end:\n",
    "            return path\n",
    "        \n",
    "        if start not in self.adjacency_list:\n",
    "            return None\n",
    "        \n",
    "        for neighbor in self.adjacency_list[start]:\n",
    "            if neighbor not in path:  # Avoid cycles\n",
    "                new_path = self.find_path(neighbor, end, path)\n",
    "                if new_path:\n",
    "                    return new_path\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def display_graph(self):\n",
    "        \"\"\"Display the graph structure\"\"\"\n",
    "        print(f\"\\nGraph ({'Directed' if self.directed else 'Undirected'}):\")\n",
    "        print(f\"Vertices: {self.vertex_count}, Edges: {self.edge_count}\")\n",
    "        \n",
    "        for vertex in sorted(self.adjacency_list.keys()):\n",
    "            neighbors = self.adjacency_list[vertex]\n",
    "            print(f\"  {vertex}: {neighbors}\")\n",
    "\n",
    "# Demo graph operations\n",
    "print(\"\\n=== Graph with Hash Table Demo ===\")\n",
    "\n",
    "# Create an undirected graph\n",
    "graph = Graph(directed=False)\n",
    "\n",
    "# Add edges (vertices are added automatically)\n",
    "edges = [\n",
    "    ('A', 'B'), ('A', 'C'), ('B', 'D'), ('C', 'D'),\n",
    "    ('D', 'E'), ('B', 'E'), ('C', 'F'), ('E', 'F')\n",
    "]\n",
    "\n",
    "for v1, v2 in edges:\n",
    "    graph.add_edge(v1, v2)\n",
    "\n",
    "graph.display_graph()\n",
    "\n",
    "# Graph traversals\n",
    "print(f\"\\nBFS from 'A': {graph.bfs('A')}\")\n",
    "print(f\"DFS from 'A': {graph.dfs('A')}\")\n",
    "\n",
    "# Path finding\n",
    "start, end = 'A', 'F'\n",
    "path = graph.find_path(start, end)\n",
    "print(f\"\\nPath from {start} to {end}: {path}\")\n",
    "\n",
    "# Check connectivity\n",
    "test_pairs = [('A', 'B'), ('A', 'F'), ('B', 'C'), ('E', 'A')]\n",
    "print(f\"\\nEdge existence:\")\n",
    "for v1, v2 in test_pairs:\n",
    "    exists = graph.has_edge(v1, v2)\n",
    "    print(f\"  {v1} -> {v2}: {exists}\")\n",
    "```\n",
    "\n",
    "These applications demonstrate hash tables' versatility:\n",
    "\n",
    "- **Database indexing**: Fast exact-match queries\n",
    "- **Caching**: O(1) cache lookups with LRU eviction\n",
    "- **Symbol tables**: Variable and function name resolution in compilers\n",
    "- **Set operations**: Efficient membership testing and set algebra\n",
    "- **Frequency analysis**: Counting and statistical operations\n",
    "- **Graph representation**: Adjacency lists for graph algorithms\n",
    "\n",
    "Hash tables excel in scenarios requiring fast key-based access, making them fundamental to many computer science applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35883f26",
   "metadata": {},
   "source": [
    "<a id=\"interview-problems\"></a>\n",
    "## Common Interview Problems\n",
    "\n",
    "Hash tables are frequently featured in technical interviews. Here are common patterns and problems with solutions.\n",
    "\n",
    "### 1. Two Sum Problem\n",
    "\n",
    "**Problem**: Given an array of integers and a target sum, return indices of two numbers that add up to the target.\n",
    "\n",
    "```python\n",
    "def two_sum(nums, target):\n",
    "    \"\"\"\n",
    "    Find two numbers that add up to target\n",
    "    \n",
    "    Time: O(n), Space: O(n)\n",
    "    \"\"\"\n",
    "    seen = {}  # value -> index\n",
    "    \n",
    "    for i, num in enumerate(nums):\n",
    "        complement = target - num\n",
    "        \n",
    "        if complement in seen:\n",
    "            return [seen[complement], i]\n",
    "        \n",
    "        seen[num] = i\n",
    "    \n",
    "    return []  # No solution found\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    ([2, 7, 11, 15], 9),      # Expected: [0, 1]\n",
    "    ([3, 2, 4], 6),           # Expected: [1, 2]\n",
    "    ([3, 3], 6),              # Expected: [0, 1]\n",
    "    ([1, 2, 3, 4, 5], 10),    # Expected: []\n",
    "]\n",
    "\n",
    "print(\"=== Two Sum Problem ===\")\n",
    "for nums, target in test_cases:\n",
    "    result = two_sum(nums, target)\n",
    "    print(f\"nums={nums}, target={target} -> {result}\")\n",
    "    if result:\n",
    "        print(f\"  Verification: {nums[result[0]]} + {nums[result[1]]} = {nums[result[0]] + nums[result[1]]}\")\n",
    "```\n",
    "\n",
    "### 2. Group Anagrams\n",
    "\n",
    "**Problem**: Group strings that are anagrams of each other.\n",
    "\n",
    "```python\n",
    "def group_anagrams(strs):\n",
    "    \"\"\"\n",
    "    Group anagrams together\n",
    "    \n",
    "    Time: O(n * k log k) where n = number of strings, k = max string length\n",
    "    Space: O(n * k)\n",
    "    \"\"\"\n",
    "    anagram_groups = {}\n",
    "    \n",
    "    for string in strs:\n",
    "        # Sort characters to create a key for anagrams\n",
    "        sorted_chars = ''.join(sorted(string))\n",
    "        \n",
    "        if sorted_chars not in anagram_groups:\n",
    "            anagram_groups[sorted_chars] = []\n",
    "        \n",
    "        anagram_groups[sorted_chars].append(string)\n",
    "    \n",
    "    return list(anagram_groups.values())\n",
    "\n",
    "def group_anagrams_optimized(strs):\n",
    "    \"\"\"\n",
    "    Optimized version using character frequency as key\n",
    "    \n",
    "    Time: O(n * k) where n = number of strings, k = max string length\n",
    "    Space: O(n * k)\n",
    "    \"\"\"\n",
    "    anagram_groups = {}\n",
    "    \n",
    "    for string in strs:\n",
    "        # Count character frequencies\n",
    "        char_count = [0] * 26\n",
    "        for char in string:\n",
    "            char_count[ord(char) - ord('a')] += 1\n",
    "        \n",
    "        # Use tuple of counts as key (tuples are hashable)\n",
    "        key = tuple(char_count)\n",
    "        \n",
    "        if key not in anagram_groups:\n",
    "            anagram_groups[key] = []\n",
    "        \n",
    "        anagram_groups[key].append(string)\n",
    "    \n",
    "    return list(anagram_groups.values())\n",
    "\n",
    "# Test the anagram grouping\n",
    "test_strings = [\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"]\n",
    "print(\"\\n=== Group Anagrams Problem ===\")\n",
    "print(f\"Input: {test_strings}\")\n",
    "print(f\"Grouped (sorting): {group_anagrams(test_strings)}\")\n",
    "print(f\"Grouped (optimized): {group_anagrams_optimized(test_strings)}\")\n",
    "```\n",
    "\n",
    "### 3. First Non-Repeating Character\n",
    "\n",
    "**Problem**: Find the first character that appears exactly once in a string.\n",
    "\n",
    "```python\n",
    "def first_unique_char(s):\n",
    "    \"\"\"\n",
    "    Find index of first non-repeating character\n",
    "    \n",
    "    Time: O(n), Space: O(1) - at most 26 characters\n",
    "    \"\"\"\n",
    "    char_count = {}\n",
    "    \n",
    "    # Count frequency of each character\n",
    "    for char in s:\n",
    "        char_count[char] = char_count.get(char, 0) + 1\n",
    "    \n",
    "    # Find first character with count 1\n",
    "    for i, char in enumerate(s):\n",
    "        if char_count[char] == 1:\n",
    "            return i\n",
    "    \n",
    "    return -1  # No unique character found\n",
    "\n",
    "def first_unique_char_optimized(s):\n",
    "    \"\"\"\n",
    "    Optimized version with early termination\n",
    "    \"\"\"\n",
    "    char_count = {}\n",
    "    char_positions = {}\n",
    "    \n",
    "    # Single pass to count and track first positions\n",
    "    for i, char in enumerate(s):\n",
    "        if char in char_count:\n",
    "            char_count[char] += 1\n",
    "        else:\n",
    "            char_count[char] = 1\n",
    "            char_positions[char] = i\n",
    "    \n",
    "    # Find minimum position among unique characters\n",
    "    min_position = len(s)\n",
    "    for char, count in char_count.items():\n",
    "        if count == 1:\n",
    "            min_position = min(min_position, char_positions[char])\n",
    "    \n",
    "    return min_position if min_position < len(s) else -1\n",
    "\n",
    "# Test cases\n",
    "test_strings = [\n",
    "    \"leetcode\",      # Expected: 0 ('l')\n",
    "    \"loveleetcode\",  # Expected: 2 ('v')\n",
    "    \"aabbcc\",        # Expected: -1\n",
    "    \"abcdef\",        # Expected: 0 ('a')\n",
    "]\n",
    "\n",
    "print(\"\\n=== First Non-Repeating Character ===\")\n",
    "for s in test_strings:\n",
    "    result = first_unique_char(s)\n",
    "    char = s[result] if result != -1 else \"None\"\n",
    "    print(f\"'{s}' -> index {result} ('{char}')\")\n",
    "```\n",
    "\n",
    "### 4. Longest Substring Without Repeating Characters\n",
    "\n",
    "**Problem**: Find the length of the longest substring without repeating characters.\n",
    "\n",
    "```python\n",
    "def length_of_longest_substring(s):\n",
    "    \"\"\"\n",
    "    Sliding window approach using hash table\n",
    "    \n",
    "    Time: O(n), Space: O(min(m, n)) where m is character set size\n",
    "    \"\"\"\n",
    "    char_index = {}  # char -> most recent index\n",
    "    left = 0  # Left pointer of sliding window\n",
    "    max_length = 0\n",
    "    \n",
    "    for right, char in enumerate(s):\n",
    "        if char in char_index and char_index[char] >= left:\n",
    "            # Character repeated in current window\n",
    "            left = char_index[char] + 1\n",
    "        \n",
    "        char_index[char] = right\n",
    "        max_length = max(max_length, right - left + 1)\n",
    "    \n",
    "    return max_length\n",
    "\n",
    "def length_of_longest_substring_with_details(s):\n",
    "    \"\"\"\n",
    "    Version that also returns the longest substring\n",
    "    \"\"\"\n",
    "    char_index = {}\n",
    "    left = 0\n",
    "    max_length = 0\n",
    "    best_start = 0\n",
    "    best_end = 0\n",
    "    \n",
    "    for right, char in enumerate(s):\n",
    "        if char in char_index and char_index[char] >= left:\n",
    "            left = char_index[char] + 1\n",
    "        \n",
    "        char_index[char] = right\n",
    "        \n",
    "        if right - left + 1 > max_length:\n",
    "            max_length = right - left + 1\n",
    "            best_start = left\n",
    "            best_end = right\n",
    "    \n",
    "    return max_length, s[best_start:best_end + 1]\n",
    "\n",
    "# Test cases\n",
    "test_strings = [\n",
    "    \"abcabcbb\",      # Expected: 3 (\"abc\")\n",
    "    \"bbbbb\",         # Expected: 1 (\"b\")\n",
    "    \"pwwkew\",        # Expected: 3 (\"wke\")\n",
    "    \"abcdef\",        # Expected: 6 (\"abcdef\")\n",
    "    \"\",              # Expected: 0\n",
    "]\n",
    "\n",
    "print(\"\\n=== Longest Substring Without Repeating Characters ===\")\n",
    "for s in test_strings:\n",
    "    length = length_of_longest_substring(s)\n",
    "    length_detailed, substring = length_of_longest_substring_with_details(s)\n",
    "    print(f\"'{s}' -> length {length}, substring: '{substring}'\")\n",
    "```\n",
    "\n",
    "### 5. Subarray Sum Equals K\n",
    "\n",
    "**Problem**: Find the number of continuous subarrays whose sum equals k.\n",
    "\n",
    "```python\n",
    "def subarray_sum(nums, k):\n",
    "    \"\"\"\n",
    "    Count subarrays with sum equal to k using prefix sums\n",
    "    \n",
    "    Time: O(n), Space: O(n)\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    prefix_sum = 0\n",
    "    sum_counts = {0: 1}  # prefix_sum -> frequency\n",
    "    \n",
    "    for num in nums:\n",
    "        prefix_sum += num\n",
    "        \n",
    "        # Check if (prefix_sum - k) exists\n",
    "        # This means there's a subarray ending at current position with sum k\n",
    "        if (prefix_sum - k) in sum_counts:\n",
    "            count += sum_counts[prefix_sum - k]\n",
    "        \n",
    "        # Update frequency of current prefix sum\n",
    "        sum_counts[prefix_sum] = sum_counts.get(prefix_sum, 0) + 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "def subarray_sum_with_indices(nums, k):\n",
    "    \"\"\"\n",
    "    Find all subarrays with sum equal to k (return start and end indices)\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    prefix_sum = 0\n",
    "    sum_indices = {0: [-1]}  # prefix_sum -> list of indices\n",
    "    \n",
    "    for i, num in enumerate(nums):\n",
    "        prefix_sum += num\n",
    "        \n",
    "        # Check if (prefix_sum - k) exists\n",
    "        if (prefix_sum - k) in sum_indices:\n",
    "            for start_index in sum_indices[prefix_sum - k]:\n",
    "                result.append((start_index + 1, i))\n",
    "        \n",
    "        # Update indices for current prefix sum\n",
    "        if prefix_sum not in sum_indices:\n",
    "            sum_indices[prefix_sum] = []\n",
    "        sum_indices[prefix_sum].append(i)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    ([1, 1, 1], 2),           # Expected: 2\n",
    "    ([1, 2, 3], 3),           # Expected: 2\n",
    "    ([1, -1, 0], 0),          # Expected: 3\n",
    "    ([1, 2, 1, 2, 1], 3),     # Expected: 4\n",
    "]\n",
    "\n",
    "print(\"\\n=== Subarray Sum Equals K ===\")\n",
    "for nums, k in test_cases:\n",
    "    count = subarray_sum(nums, k)\n",
    "    indices = subarray_sum_with_indices(nums, k)\n",
    "    print(f\"nums={nums}, k={k} -> count: {count}\")\n",
    "    print(f\"  Subarrays: {indices}\")\n",
    "    \n",
    "    # Verify subarrays\n",
    "    for start, end in indices:\n",
    "        subarray = nums[start:end+1]\n",
    "        subarray_sum_val = sum(subarray)\n",
    "        print(f\"    {subarray} (sum={subarray_sum_val})\")\n",
    "```\n",
    "\n",
    "### 6. Valid Anagram\n",
    "\n",
    "**Problem**: Determine if two strings are anagrams of each other.\n",
    "\n",
    "```python\n",
    "def is_anagram(s, t):\n",
    "    \"\"\"\n",
    "    Check if two strings are anagrams using hash table\n",
    "    \n",
    "    Time: O(n), Space: O(1) - at most 26 characters\n",
    "    \"\"\"\n",
    "    if len(s) != len(t):\n",
    "        return False\n",
    "    \n",
    "    char_count = {}\n",
    "    \n",
    "    # Count characters in first string\n",
    "    for char in s:\n",
    "        char_count[char] = char_count.get(char, 0) + 1\n",
    "    \n",
    "    # Subtract character counts using second string\n",
    "    for char in t:\n",
    "        if char not in char_count:\n",
    "            return False\n",
    "        char_count[char] -= 1\n",
    "        if char_count[char] == 0:\n",
    "            del char_count[char]\n",
    "    \n",
    "    return len(char_count) == 0\n",
    "\n",
    "def is_anagram_optimized(s, t):\n",
    "    \"\"\"\n",
    "    Optimized version using array for counting (only for lowercase letters)\n",
    "    \"\"\"\n",
    "    if len(s) != len(t):\n",
    "        return False\n",
    "    \n",
    "    counts = [0] * 26\n",
    "    \n",
    "    for i in range(len(s)):\n",
    "        counts[ord(s[i]) - ord('a')] += 1\n",
    "        counts[ord(t[i]) - ord('a')] -= 1\n",
    "    \n",
    "    return all(count == 0 for count in counts)\n",
    "\n",
    "# Test cases\n",
    "anagram_pairs = [\n",
    "    (\"anagram\", \"nagaram\"),   # True\n",
    "    (\"rat\", \"car\"),           # False\n",
    "    (\"listen\", \"silent\"),     # True\n",
    "    (\"evil\", \"vile\"),         # True\n",
    "    (\"hello\", \"bello\"),       # False\n",
    "]\n",
    "\n",
    "print(\"\\n=== Valid Anagram ===\")\n",
    "for s, t in anagram_pairs:\n",
    "    result = is_anagram(s, t)\n",
    "    result_opt = is_anagram_optimized(s, t)\n",
    "    print(f\"'{s}' and '{t}' are anagrams: {result} (optimized: {result_opt})\")\n",
    "```\n",
    "\n",
    "### 7. Top K Frequent Elements\n",
    "\n",
    "**Problem**: Find the k most frequent elements in an array.\n",
    "\n",
    "```python\n",
    "import heapq\n",
    "from collections import Counter\n",
    "\n",
    "def top_k_frequent(nums, k):\n",
    "    \"\"\"\n",
    "    Find k most frequent elements using hash table + heap\n",
    "    \n",
    "    Time: O(n log k), Space: O(n)\n",
    "    \"\"\"\n",
    "    # Count frequencies\n",
    "    freq_count = {}\n",
    "    for num in nums:\n",
    "        freq_count[num] = freq_count.get(num, 0) + 1\n",
    "    \n",
    "    # Use min heap to keep track of top k elements\n",
    "    heap = []\n",
    "    \n",
    "    for num, freq in freq_count.items():\n",
    "        heapq.heappush(heap, (freq, num))\n",
    "        if len(heap) > k:\n",
    "            heapq.heappop(heap)\n",
    "    \n",
    "    # Extract elements from heap\n",
    "    result = []\n",
    "    while heap:\n",
    "        freq, num = heapq.heappop(heap)\n",
    "        result.append(num)\n",
    "    \n",
    "    return result[::-1]  # Reverse to get descending order\n",
    "\n",
    "def top_k_frequent_bucket_sort(nums, k):\n",
    "    \"\"\"\n",
    "    Optimized version using bucket sort\n",
    "    \n",
    "    Time: O(n), Space: O(n)\n",
    "    \"\"\"\n",
    "    # Count frequencies\n",
    "    freq_count = Counter(nums)\n",
    "    \n",
    "    # Bucket sort: index = frequency, value = list of numbers with that frequency\n",
    "    buckets = [[] for _ in range(len(nums) + 1)]\n",
    "    \n",
    "    for num, freq in freq_count.items():\n",
    "        buckets[freq].append(num)\n",
    "    \n",
    "    # Collect top k elements from highest frequency buckets\n",
    "    result = []\n",
    "    for freq in range(len(buckets) - 1, 0, -1):\n",
    "        for num in buckets[freq]:\n",
    "            result.append(num)\n",
    "            if len(result) == k:\n",
    "                return result\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    ([1, 1, 1, 2, 2, 3], 2),      # Expected: [1, 2]\n",
    "    ([1], 1),                     # Expected: [1]\n",
    "    ([1, 2, 3, 1, 2, 1], 2),      # Expected: [1, 2]\n",
    "    ([4, 1, -1, 2, -1, 2, 3], 2), # Expected: [-1, 2] or [2, -1]\n",
    "]\n",
    "\n",
    "print(\"\\n=== Top K Frequent Elements ===\")\n",
    "for nums, k in test_cases:\n",
    "    result_heap = top_k_frequent(nums, k)\n",
    "    result_bucket = top_k_frequent_bucket_sort(nums, k)\n",
    "    \n",
    "    print(f\"nums={nums}, k={k}\")\n",
    "    print(f\"  Heap method: {result_heap}\")\n",
    "    print(f\"  Bucket sort: {result_bucket}\")\n",
    "    \n",
    "    # Show frequencies for verification\n",
    "    freq_count = Counter(nums)\n",
    "    sorted_by_freq = sorted(freq_count.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(f\"  All frequencies: {sorted_by_freq}\")\n",
    "```\n",
    "\n",
    "### Key Interview Tips for Hash Table Problems\n",
    "\n",
    "1. **Time/Space Complexity**: Most hash table operations are O(1) average case\n",
    "2. **Common Patterns**:\n",
    "   - **Two-pointer with hash table**: Two Sum, Three Sum\n",
    "   - **Sliding window with hash table**: Longest substring problems\n",
    "   - **Frequency counting**: Anagrams, character problems\n",
    "   - **Prefix sums**: Subarray sum problems\n",
    "   - **Caching/Memoization**: Dynamic programming optimizations\n",
    "\n",
    "3. **Edge Cases to Consider**:\n",
    "   - Empty input\n",
    "   - Single element\n",
    "   - All elements same\n",
    "   - No valid solution\n",
    "   - Negative numbers (for sum problems)\n",
    "\n",
    "4. **Space Optimization**:\n",
    "   - Use arrays instead of hash tables for small character sets\n",
    "   - Consider in-place algorithms when possible\n",
    "   - Use bit manipulation for boolean flags\n",
    "\n",
    "5. **Follow-up Questions**:\n",
    "   - \"What if we can't use extra space?\"\n",
    "   - \"What if the input is sorted?\"\n",
    "   - \"What if there are duplicates?\"\n",
    "   - \"How would you handle very large inputs?\"\n",
    "\n",
    "These problems demonstrate the most common hash table patterns in technical interviews, emphasizing the importance of understanding when and how to apply hash tables for optimal solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b9747f",
   "metadata": {},
   "source": [
    "<a id=\"comparison-with-other-structures\"></a>\n",
    "## Comparison with Other Data Structures\n",
    "\n",
    "Understanding when to use hash tables versus other data structures is crucial for making optimal design decisions.\n",
    "\n",
    "### Hash Tables vs Arrays\n",
    "\n",
    "| Aspect | Hash Table | Array |\n",
    "|--------|------------|--------|\n",
    "| **Access by Key** | O(1) average | O(n) search |\n",
    "| **Access by Index** | Not applicable | O(1) |\n",
    "| **Insertion** | O(1) average | O(1) end, O(n) middle |\n",
    "| **Deletion** | O(1) average | O(n) |\n",
    "| **Memory Usage** | Higher overhead | Minimal overhead |\n",
    "| **Cache Performance** | Poor (scattered) | Excellent (contiguous) |\n",
    "| **Ordering** | No inherent order | Maintains insertion order |\n",
    "\n",
    "```python\n",
    "import time\n",
    "import random\n",
    "\n",
    "def compare_hash_vs_array():\n",
    "    \"\"\"Compare performance of hash table vs array for different operations\"\"\"\n",
    "    \n",
    "    # Setup data\n",
    "    size = 10000\n",
    "    data = list(range(size))\n",
    "    search_keys = random.sample(data, 1000)\n",
    "    \n",
    "    # Array implementation\n",
    "    array_data = data.copy()\n",
    "    \n",
    "    # Hash table implementation\n",
    "    hash_data = {key: f\"value_{key}\" for key in data}\n",
    "    \n",
    "    print(\"=== Hash Table vs Array Performance ===\")\n",
    "    \n",
    "    # Search performance\n",
    "    # Array linear search\n",
    "    start_time = time.time()\n",
    "    array_found = 0\n",
    "    for key in search_keys:\n",
    "        if key in array_data:  # Linear search\n",
    "            array_found += 1\n",
    "    array_search_time = time.time() - start_time\n",
    "    \n",
    "    # Hash table lookup\n",
    "    start_time = time.time()\n",
    "    hash_found = 0\n",
    "    for key in search_keys:\n",
    "        if key in hash_data:  # O(1) lookup\n",
    "            hash_found += 1\n",
    "    hash_search_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Search Performance (1000 lookups):\")\n",
    "    print(f\"  Array (linear search): {array_search_time:.4f}s\")\n",
    "    print(f\"  Hash Table: {hash_search_time:.4f}s\")\n",
    "    print(f\"  Speedup: {array_search_time / hash_search_time:.1f}x\")\n",
    "    \n",
    "    # Insertion performance\n",
    "    # Array append\n",
    "    start_time = time.time()\n",
    "    for i in range(1000):\n",
    "        array_data.append(size + i)\n",
    "    array_insert_time = time.time() - start_time\n",
    "    \n",
    "    # Hash table insertion\n",
    "    start_time = time.time()\n",
    "    for i in range(1000):\n",
    "        hash_data[size + i] = f\"value_{size + i}\"\n",
    "    hash_insert_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nInsertion Performance (1000 insertions):\")\n",
    "    print(f\"  Array (append): {array_insert_time:.4f}s\")\n",
    "    print(f\"  Hash Table: {hash_insert_time:.4f}s\")\n",
    "\n",
    "compare_hash_vs_array()\n",
    "```\n",
    "\n",
    "### Hash Tables vs Linked Lists\n",
    "\n",
    "| Aspect | Hash Table | Linked List |\n",
    "|--------|------------|-------------|\n",
    "| **Search** | O(1) average | O(n) |\n",
    "| **Insertion** | O(1) average | O(1) at head |\n",
    "| **Deletion** | O(1) average | O(1) with reference |\n",
    "| **Memory Usage** | Higher overhead | Node overhead |\n",
    "| **Cache Performance** | Poor | Poor |\n",
    "| **Ordering** | No inherent order | Maintains order |\n",
    "\n",
    "```python\n",
    "class LinkedListNode:\n",
    "    def __init__(self, key, value):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.next = None\n",
    "\n",
    "class SimpleLinkedList:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "    \n",
    "    def insert(self, key, value):\n",
    "        new_node = LinkedListNode(key, value)\n",
    "        new_node.next = self.head\n",
    "        self.head = new_node\n",
    "    \n",
    "    def search(self, key):\n",
    "        current = self.head\n",
    "        while current:\n",
    "            if current.key == key:\n",
    "                return current.value\n",
    "            current = current.next\n",
    "        return None\n",
    "    \n",
    "    def delete(self, key):\n",
    "        if not self.head:\n",
    "            return False\n",
    "        \n",
    "        if self.head.key == key:\n",
    "            self.head = self.head.next\n",
    "            return True\n",
    "        \n",
    "        current = self.head\n",
    "        while current.next:\n",
    "            if current.next.key == key:\n",
    "                current.next = current.next.next\n",
    "                return True\n",
    "            current = current.next\n",
    "        return False\n",
    "\n",
    "def compare_hash_vs_linkedlist():\n",
    "    \"\"\"Compare hash table vs linked list performance\"\"\"\n",
    "    \n",
    "    # Setup\n",
    "    size = 1000\n",
    "    keys = list(range(size))\n",
    "    \n",
    "    # Create data structures\n",
    "    hash_table = {key: f\"value_{key}\" for key in keys}\n",
    "    linked_list = SimpleLinkedList()\n",
    "    for key in keys:\n",
    "        linked_list.insert(key, f\"value_{key}\")\n",
    "    \n",
    "    # Search comparison\n",
    "    search_keys = random.sample(keys, 100)\n",
    "    \n",
    "    # Hash table search\n",
    "    start_time = time.time()\n",
    "    for key in search_keys:\n",
    "        hash_table.get(key)\n",
    "    hash_time = time.time() - start_time\n",
    "    \n",
    "    # Linked list search\n",
    "    start_time = time.time()\n",
    "    for key in search_keys:\n",
    "        linked_list.search(key)\n",
    "    list_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n=== Hash Table vs Linked List (100 searches) ===\")\n",
    "    print(f\"Hash Table: {hash_time:.4f}s\")\n",
    "    print(f\"Linked List: {list_time:.4f}s\")\n",
    "    print(f\"Speedup: {list_time / hash_time:.1f}x\")\n",
    "\n",
    "compare_hash_vs_linkedlist()\n",
    "```\n",
    "\n",
    "### Hash Tables vs Binary Search Trees\n",
    "\n",
    "| Aspect | Hash Table | Binary Search Tree |\n",
    "|--------|------------|-------------------|\n",
    "| **Search** | O(1) average, O(n) worst | O(log n) average, O(n) worst |\n",
    "| **Insertion** | O(1) average | O(log n) average |\n",
    "| **Deletion** | O(1) average | O(log n) average |\n",
    "| **Ordering** | No inherent order | Maintains sorted order |\n",
    "| **Range Queries** | Not supported | O(log n + k) |\n",
    "| **Memory Usage** | Higher overhead | Node overhead |\n",
    "\n",
    "```python\n",
    "class BSTNode:\n",
    "    def __init__(self, key, value):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "class SimpleBST:\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "    \n",
    "    def insert(self, key, value):\n",
    "        self.root = self._insert_recursive(self.root, key, value)\n",
    "    \n",
    "    def _insert_recursive(self, node, key, value):\n",
    "        if not node:\n",
    "            return BSTNode(key, value)\n",
    "        \n",
    "        if key < node.key:\n",
    "            node.left = self._insert_recursive(node.left, key, value)\n",
    "        elif key > node.key:\n",
    "            node.right = self._insert_recursive(node.right, key, value)\n",
    "        else:\n",
    "            node.value = value  # Update existing key\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def search(self, key):\n",
    "        return self._search_recursive(self.root, key)\n",
    "    \n",
    "    def _search_recursive(self, node, key):\n",
    "        if not node or node.key == key:\n",
    "            return node.value if node else None\n",
    "        \n",
    "        if key < node.key:\n",
    "            return self._search_recursive(node.left, key)\n",
    "        else:\n",
    "            return self._search_recursive(node.right, key)\n",
    "    \n",
    "    def range_query(self, min_key, max_key):\n",
    "        \"\"\"Find all keys in range [min_key, max_key] - not possible with hash table\"\"\"\n",
    "        result = []\n",
    "        self._range_query_recursive(self.root, min_key, max_key, result)\n",
    "        return result\n",
    "    \n",
    "    def _range_query_recursive(self, node, min_key, max_key, result):\n",
    "        if not node:\n",
    "            return\n",
    "        \n",
    "        if min_key <= node.key <= max_key:\n",
    "            result.append((node.key, node.value))\n",
    "        \n",
    "        if node.key > min_key:\n",
    "            self._range_query_recursive(node.left, min_key, max_key, result)\n",
    "        \n",
    "        if node.key < max_key:\n",
    "            self._range_query_recursive(node.right, min_key, max_key, result)\n",
    "\n",
    "def compare_hash_vs_bst():\n",
    "    \"\"\"Compare hash table vs BST for different operations\"\"\"\n",
    "    \n",
    "    # Setup\n",
    "    keys = list(range(1000))\n",
    "    random.shuffle(keys)  # Random insertion order for BST\n",
    "    \n",
    "    # Build data structures\n",
    "    hash_table = {}\n",
    "    bst = SimpleBST()\n",
    "    \n",
    "    # Insertion timing\n",
    "    start_time = time.time()\n",
    "    for key in keys:\n",
    "        hash_table[key] = f\"value_{key}\"\n",
    "    hash_insert_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for key in keys:\n",
    "        bst.insert(key, f\"value_{key}\")\n",
    "    bst_insert_time = time.time() - start_time\n",
    "    \n",
    "    # Search timing\n",
    "    search_keys = random.sample(keys, 100)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for key in search_keys:\n",
    "        hash_table.get(key)\n",
    "    hash_search_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for key in search_keys:\n",
    "        bst.search(key)\n",
    "    bst_search_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n=== Hash Table vs BST Performance ===\")\n",
    "    print(f\"Insertion (1000 items):\")\n",
    "    print(f\"  Hash Table: {hash_insert_time:.4f}s\")\n",
    "    print(f\"  BST: {bst_insert_time:.4f}s\")\n",
    "    \n",
    "    print(f\"\\nSearch (100 lookups):\")\n",
    "    print(f\"  Hash Table: {hash_search_time:.4f}s\")\n",
    "    print(f\"  BST: {bst_search_time:.4f}s\")\n",
    "    \n",
    "    # Range query (only BST supports this)\n",
    "    range_results = bst.range_query(100, 200)\n",
    "    print(f\"\\nRange Query [100, 200]: BST found {len(range_results)} items\")\n",
    "    print(f\"  Sample results: {range_results[:5]}\")\n",
    "    print(f\"  Hash tables cannot efficiently perform range queries\")\n",
    "\n",
    "compare_hash_vs_bst()\n",
    "```\n",
    "\n",
    "### Hash Tables vs Sets and Maps\n",
    "\n",
    "Different languages provide various hash-based data structures:\n",
    "\n",
    "```python\n",
    "def compare_builtin_structures():\n",
    "    \"\"\"Compare Python's built-in hash-based structures\"\"\"\n",
    "    \n",
    "    data = list(range(1000))\n",
    "    \n",
    "    # Different ways to store key-value pairs\n",
    "    structures = {\n",
    "        'dict': dict(enumerate(data)),\n",
    "        'defaultdict': __import__('collections').defaultdict(int),\n",
    "        'OrderedDict': __import__('collections').OrderedDict(enumerate(data)),\n",
    "        'set': set(data),  # For membership testing only\n",
    "    }\n",
    "    \n",
    "    # Fill defaultdict\n",
    "    for i, value in enumerate(data):\n",
    "        structures['defaultdict'][i] = value\n",
    "    \n",
    "    print(f\"\\n=== Built-in Hash Structures Comparison ===\")\n",
    "    \n",
    "    # Memory usage (approximate)\n",
    "    import sys\n",
    "    for name, structure in structures.items():\n",
    "        memory = sys.getsizeof(structure)\n",
    "        print(f\"{name}: ~{memory} bytes ({memory/len(data):.1f} per item)\")\n",
    "    \n",
    "    # Performance characteristics\n",
    "    search_keys = random.sample(data, 100)\n",
    "    \n",
    "    for name, structure in structures.items():\n",
    "        if name == 'set':\n",
    "            # Test membership\n",
    "            start_time = time.time()\n",
    "            for key in search_keys:\n",
    "                key in structure\n",
    "            time_taken = time.time() - start_time\n",
    "        else:\n",
    "            # Test key lookup\n",
    "            start_time = time.time()\n",
    "            for key in search_keys:\n",
    "                structure.get(key) if hasattr(structure, 'get') else structure[key]\n",
    "            time_taken = time.time() - start_time\n",
    "        \n",
    "        print(f\"{name} lookup time: {time_taken:.6f}s\")\n",
    "\n",
    "compare_builtin_structures()\n",
    "```\n",
    "\n",
    "### When to Use Each Data Structure\n",
    "\n",
    "#### Use Hash Tables When:\n",
    "- **Fast key-based lookup** is primary requirement\n",
    "- **Average-case O(1) performance** is acceptable\n",
    "- **Order doesn't matter**\n",
    "- **Memory overhead is acceptable**\n",
    "- **Implementing caches, symbol tables, or frequency counters**\n",
    "\n",
    "#### Use Arrays When:\n",
    "- **Index-based access** is needed\n",
    "- **Cache performance** is critical\n",
    "- **Memory usage** must be minimized\n",
    "- **Sequential processing** is common\n",
    "- **Numerical computations** are primary use case\n",
    "\n",
    "#### Use Linked Lists When:\n",
    "- **Frequent insertions/deletions** at arbitrary positions\n",
    "- **Memory allocation** needs to be dynamic\n",
    "- **Don't know final size** in advance\n",
    "- **Sequential access** is primary pattern\n",
    "\n",
    "#### Use Binary Search Trees When:\n",
    "- **Sorted order** must be maintained\n",
    "- **Range queries** are needed\n",
    "- **Predictable O(log n) performance** is required\n",
    "- **In-order traversal** provides useful ordering\n",
    "\n",
    "### Hybrid Approaches\n",
    "\n",
    "```python\n",
    "class HashTableWithOrdering:\n",
    "    \"\"\"Hash table that also maintains insertion order\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = {}  # key -> (value, order)\n",
    "        self.order = []  # maintain insertion order\n",
    "        self.next_order = 0\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        if key not in self.data:\n",
    "            self.order.append(key)\n",
    "        self.data[key] = (value, self.next_order)\n",
    "        self.next_order += 1\n",
    "    \n",
    "    def get(self, key):\n",
    "        return self.data[key][0] if key in self.data else None\n",
    "    \n",
    "    def items_by_insertion_order(self):\n",
    "        \"\"\"Get items in insertion order\"\"\"\n",
    "        return [(key, self.data[key][0]) for key in self.order if key in self.data]\n",
    "    \n",
    "    def items_by_access_order(self):\n",
    "        \"\"\"Get items by access order\"\"\"\n",
    "        return sorted(self.data.items(), key=lambda x: x[1][1])\n",
    "\n",
    "# Example of when you might need multiple data structures\n",
    "class OptimizedDatabase:\n",
    "    \"\"\"Database that uses multiple data structures for different query types\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.primary_index = {}      # Hash table for O(1) primary key lookup\n",
    "        self.secondary_index = {}    # Hash table for secondary key lookup\n",
    "        self.range_index = SimpleBST()  # BST for range queries\n",
    "        self.data = []              # Array for sequential scans\n",
    "    \n",
    "    def insert(self, primary_key, secondary_key, data):\n",
    "        record = {\n",
    "            'primary_key': primary_key,\n",
    "            'secondary_key': secondary_key,\n",
    "            'data': data,\n",
    "            'position': len(self.data)\n",
    "        }\n",
    "        \n",
    "        # Update all indexes\n",
    "        self.primary_index[primary_key] = record\n",
    "        if secondary_key not in self.secondary_index:\n",
    "            self.secondary_index[secondary_key] = []\n",
    "        self.secondary_index[secondary_key].append(record)\n",
    "        self.range_index.insert(primary_key, record)\n",
    "        self.data.append(record)\n",
    "    \n",
    "    def find_by_primary_key(self, key):\n",
    "        \"\"\"O(1) primary key lookup\"\"\"\n",
    "        return self.primary_index.get(key)\n",
    "    \n",
    "    def find_by_secondary_key(self, key):\n",
    "        \"\"\"O(1) secondary key lookup\"\"\"\n",
    "        return self.secondary_index.get(key, [])\n",
    "    \n",
    "    def find_by_range(self, min_key, max_key):\n",
    "        \"\"\"O(log n + k) range query\"\"\"\n",
    "        return self.range_index.range_query(min_key, max_key)\n",
    "    \n",
    "    def sequential_scan(self):\n",
    "        \"\"\"O(n) full table scan with good cache performance\"\"\"\n",
    "        return self.data\n",
    "\n",
    "print(f\"\\n=== Hybrid Data Structure Example ===\")\n",
    "db = OptimizedDatabase()\n",
    "\n",
    "# Insert some data\n",
    "for i in range(10):\n",
    "    db.insert(i, f\"group_{i % 3}\", f\"data_{i}\")\n",
    "\n",
    "print(f\"Primary key lookup (5): {db.find_by_primary_key(5)}\")\n",
    "print(f\"Secondary key lookup ('group_1'): {len(db.find_by_secondary_key('group_1'))} records\")\n",
    "print(f\"Range query [3, 7]: {len(db.find_by_range(3, 7))} records\")\n",
    "print(f\"Sequential scan: {len(db.sequential_scan())} total records\")\n",
    "```\n",
    "\n",
    "### Summary of Trade-offs\n",
    "\n",
    "The choice of data structure depends on your specific requirements:\n",
    "\n",
    "1. **Performance Requirements**: Average vs worst-case guarantees\n",
    "2. **Access Patterns**: Random access, sequential, range queries\n",
    "3. **Memory Constraints**: Space complexity and overhead\n",
    "4. **Ordering Requirements**: Need for sorted data\n",
    "5. **Operation Mix**: Read-heavy, write-heavy, or balanced workload\n",
    "\n",
    "Hash tables excel at key-based operations but sacrifice ordering and range query capabilities. Understanding these trade-offs helps you choose the right tool for each specific problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40c3454",
   "metadata": {},
   "source": [
    "<a id=\"when-to-use\"></a>\n",
    "## When to Use Hash Tables\n",
    "\n",
    "Making the right choice about when to use hash tables is crucial for optimal system design and performance.\n",
    "\n",
    "### Ideal Use Cases for Hash Tables\n",
    "\n",
    "#### 1. Fast Key-Based Lookups\n",
    "Hash tables are perfect when you need O(1) average-case lookup performance:\n",
    "\n",
    "```python\n",
    "# Example: User session management\n",
    "class SessionManager:\n",
    "    \"\"\"Manages user sessions using hash table for fast lookup\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sessions = {}  # session_id -> session_data\n",
    "        self.user_sessions = {}  # user_id -> set of session_ids\n",
    "    \n",
    "    def create_session(self, user_id, session_id, session_data):\n",
    "        \"\"\"Create new session - O(1)\"\"\"\n",
    "        self.sessions[session_id] = {\n",
    "            'user_id': user_id,\n",
    "            'data': session_data,\n",
    "            'created_at': time.time()\n",
    "        }\n",
    "        \n",
    "        if user_id not in self.user_sessions:\n",
    "            self.user_sessions[user_id] = set()\n",
    "        self.user_sessions[user_id].add(session_id)\n",
    "    \n",
    "    def get_session(self, session_id):\n",
    "        \"\"\"Retrieve session - O(1)\"\"\"\n",
    "        return self.sessions.get(session_id)\n",
    "    \n",
    "    def invalidate_session(self, session_id):\n",
    "        \"\"\"Remove session - O(1)\"\"\"\n",
    "        if session_id in self.sessions:\n",
    "            user_id = self.sessions[session_id]['user_id']\n",
    "            del self.sessions[session_id]\n",
    "            self.user_sessions[user_id].discard(session_id)\n",
    "    \n",
    "    def get_user_sessions(self, user_id):\n",
    "        \"\"\"Get all sessions for user - O(k) where k is number of sessions\"\"\"\n",
    "        session_ids = self.user_sessions.get(user_id, set())\n",
    "        return [self.sessions[sid] for sid in session_ids if sid in self.sessions]\n",
    "\n",
    "# Demo session management\n",
    "print(\"=== Session Management Example ===\")\n",
    "session_mgr = SessionManager()\n",
    "\n",
    "# Create sessions\n",
    "session_mgr.create_session(\"user123\", \"sess_abc\", {\"login_time\": \"2024-01-01\"})\n",
    "session_mgr.create_session(\"user123\", \"sess_def\", {\"login_time\": \"2024-01-02\"})\n",
    "session_mgr.create_session(\"user456\", \"sess_ghi\", {\"login_time\": \"2024-01-01\"})\n",
    "\n",
    "# Fast lookups\n",
    "print(f\"Session sess_abc: {session_mgr.get_session('sess_abc')}\")\n",
    "print(f\"User123 sessions: {len(session_mgr.get_user_sessions('user123'))}\")\n",
    "```\n",
    "\n",
    "#### 2. Caching and Memoization\n",
    "Hash tables excel at implementing caches to avoid expensive recomputations:\n",
    "\n",
    "```python\n",
    "import functools\n",
    "import time\n",
    "\n",
    "def timed_lru_cache(maxsize=128):\n",
    "    \"\"\"LRU cache with timing information\"\"\"\n",
    "    def decorator(func):\n",
    "        func._cache_hits = 0\n",
    "        func._cache_misses = 0\n",
    "        func._computation_time = 0\n",
    "        \n",
    "        @functools.lru_cache(maxsize=maxsize)\n",
    "        def cached_func(*args, **kwargs):\n",
    "            return func(*args, **kwargs)\n",
    "        \n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            # Check if result is in cache\n",
    "            cache_info = cached_func.cache_info()\n",
    "            initial_hits = cache_info.hits\n",
    "            \n",
    "            start_time = time.time()\n",
    "            result = cached_func(*args, **kwargs)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            # Update statistics\n",
    "            new_cache_info = cached_func.cache_info()\n",
    "            if new_cache_info.hits > initial_hits:\n",
    "                func._cache_hits += 1\n",
    "            else:\n",
    "                func._cache_misses += 1\n",
    "                func._computation_time += (end_time - start_time)\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        wrapper.cache_info = cached_func.cache_info\n",
    "        wrapper.cache_clear = cached_func.cache_clear\n",
    "        wrapper.get_stats = lambda: {\n",
    "            'hits': func._cache_hits,\n",
    "            'misses': func._cache_misses,\n",
    "            'hit_rate': func._cache_hits / (func._cache_hits + func._cache_misses) * 100 if (func._cache_hits + func._cache_misses) > 0 else 0,\n",
    "            'computation_time': func._computation_time\n",
    "        }\n",
    "        \n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@timed_lru_cache(maxsize=100)\n",
    "def expensive_fibonacci(n):\n",
    "    \"\"\"Expensive Fibonacci calculation with caching\"\"\"\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return expensive_fibonacci(n-1) + expensive_fibonacci(n-2)\n",
    "\n",
    "# Demo caching benefits\n",
    "print(\"\\n=== Caching/Memoization Example ===\")\n",
    "print(\"Computing Fibonacci numbers with caching:\")\n",
    "\n",
    "for i in [10, 20, 30, 25, 20, 35]:  # Notice repeated values\n",
    "    start = time.time()\n",
    "    result = expensive_fibonacci(i)\n",
    "    duration = time.time() - start\n",
    "    print(f\"fib({i}) = {result} (computed in {duration:.6f}s)\")\n",
    "\n",
    "stats = expensive_fibonacci.get_stats()\n",
    "print(f\"\\nCache Statistics: {stats}\")\n",
    "print(f\"Total time saved by caching: {stats['computation_time']:.6f}s\")\n",
    "```\n",
    "\n",
    "#### 3. Frequency Counting and Statistics\n",
    "Perfect for counting occurrences and building frequency distributions:\n",
    "\n",
    "```python\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "\n",
    "class TextAnalyzer:\n",
    "    \"\"\"Analyze text using hash tables for frequency counting\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.word_freq = defaultdict(int)\n",
    "        self.bigram_freq = defaultdict(int)\n",
    "        self.char_freq = defaultdict(int)\n",
    "        self.word_positions = defaultdict(list)\n",
    "    \n",
    "    def analyze(self, text):\n",
    "        \"\"\"Comprehensive text analysis using hash tables\"\"\"\n",
    "        # Clean and tokenize\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        \n",
    "        # Word frequency and positions\n",
    "        for i, word in enumerate(words):\n",
    "            self.word_freq[word] += 1\n",
    "            self.word_positions[word].append(i)\n",
    "        \n",
    "        # Character frequency\n",
    "        for char in text.lower():\n",
    "            if char.isalpha():\n",
    "                self.char_freq[char] += 1\n",
    "        \n",
    "        # Bigram frequency\n",
    "        for i in range(len(words) - 1):\n",
    "            bigram = (words[i], words[i + 1])\n",
    "            self.bigram_freq[bigram] += 1\n",
    "    \n",
    "    def get_most_common_words(self, n=10):\n",
    "        return Counter(self.word_freq).most_common(n)\n",
    "    \n",
    "    def get_most_common_bigrams(self, n=10):\n",
    "        return Counter(self.bigram_freq).most_common(n)\n",
    "    \n",
    "    def get_word_stats(self, word):\n",
    "        return {\n",
    "            'frequency': self.word_freq[word],\n",
    "            'positions': self.word_positions[word],\n",
    "            'first_occurrence': min(self.word_positions[word]) if self.word_positions[word] else -1\n",
    "        }\n",
    "\n",
    "# Demo text analysis\n",
    "sample_text = \"\"\"\n",
    "The quick brown fox jumps over the lazy dog. The dog was very lazy,\n",
    "sleeping under the warm sun. The fox, being quick and clever, decided\n",
    "to jump over the lazy dog once more. Quick movements and lazy afternoons\n",
    "make for interesting contrasts in nature.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n=== Text Analysis Example ===\")\n",
    "analyzer = TextAnalyzer()\n",
    "analyzer.analyze(sample_text)\n",
    "\n",
    "print(\"Most common words:\")\n",
    "for word, freq in analyzer.get_most_common_words(5):\n",
    "    print(f\"  '{word}': {freq} times\")\n",
    "\n",
    "print(\"\\nMost common bigrams:\")\n",
    "for bigram, freq in analyzer.get_most_common_bigrams(5):\n",
    "    print(f\"  '{bigram[0]} {bigram[1]}': {freq} times\")\n",
    "\n",
    "print(f\"\\nWord 'the' statistics: {analyzer.get_word_stats('the')}\")\n",
    "```\n",
    "\n",
    "### When NOT to Use Hash Tables\n",
    "\n",
    "#### 1. When Order Matters\n",
    "If you need to maintain sorted order or iterate in a specific sequence:\n",
    "\n",
    "```python\n",
    "def demonstrate_ordering_limitations():\n",
    "    \"\"\"Show why hash tables are poor for ordered operations\"\"\"\n",
    "    \n",
    "    # Hash table (dictionary) - no guaranteed order\n",
    "    hash_data = {}\n",
    "    for i in [3, 1, 4, 1, 5, 9, 2, 6]:\n",
    "        hash_data[i] = f\"value_{i}\"\n",
    "    \n",
    "    # List - maintains insertion order\n",
    "    list_data = []\n",
    "    for i in [3, 1, 4, 1, 5, 9, 2, 6]:\n",
    "        if i not in [item[0] for item in list_data]:  # Avoid duplicates\n",
    "            list_data.append((i, f\"value_{i}\"))\n",
    "    \n",
    "    print(\"\\n=== Ordering Comparison ===\")\n",
    "    print(f\"Hash table keys: {list(hash_data.keys())}\")\n",
    "    print(f\"List order: {[item[0] for item in list_data]}\")\n",
    "    \n",
    "    # Sorted operations\n",
    "    print(f\"Hash table sorted: {sorted(hash_data.keys())}\")\n",
    "    print(f\"List sorted: {sorted([item[0] for item in list_data])}\")\n",
    "    \n",
    "    # Range queries are inefficient with hash tables\n",
    "    target_range = (2, 5)\n",
    "    print(f\"\\nFinding values in range {target_range}:\")\n",
    "    \n",
    "    # Hash table: must check every element O(n)\n",
    "    hash_range = [k for k in hash_data.keys() if target_range[0] <= k <= target_range[1]]\n",
    "    print(f\"Hash table result: {hash_range}\")\n",
    "    \n",
    "    # List: can use binary search if sorted O(log n)\n",
    "    list_range = [item[0] for item in list_data if target_range[0] <= item[0] <= target_range[1]]\n",
    "    print(f\"List result: {list_range}\")\n",
    "\n",
    "demonstrate_ordering_limitations()\n",
    "```\n",
    "\n",
    "#### 2. Memory-Constrained Environments\n",
    "Hash tables have overhead that may be prohibitive in memory-limited situations:\n",
    "\n",
    "```python\n",
    "import sys\n",
    "\n",
    "def compare_memory_usage():\n",
    "    \"\"\"Compare memory usage of different data structures\"\"\"\n",
    "    \n",
    "    data_size = 1000\n",
    "    \n",
    "    # Different ways to store integer pairs\n",
    "    structures = {}\n",
    "    \n",
    "    # Hash table\n",
    "    structures['dict'] = {i: i * 2 for i in range(data_size)}\n",
    "    \n",
    "    # List of tuples\n",
    "    structures['list'] = [(i, i * 2) for i in range(data_size)]\n",
    "    \n",
    "    # Two separate lists\n",
    "    structures['two_lists'] = (list(range(data_size)), [i * 2 for i in range(data_size)])\n",
    "    \n",
    "    # NumPy array (if available)\n",
    "    try:\n",
    "        import numpy as np\n",
    "        structures['numpy'] = np.array([(i, i * 2) for i in range(data_size)])\n",
    "    except ImportError:\n",
    "        structures['numpy'] = \"Not available\"\n",
    "    \n",
    "    print(\"\\n=== Memory Usage Comparison ===\")\n",
    "    for name, structure in structures.items():\n",
    "        if isinstance(structure, str):\n",
    "            print(f\"{name}: {structure}\")\n",
    "        else:\n",
    "            if name == 'two_lists':\n",
    "                memory = sys.getsizeof(structure[0]) + sys.getsizeof(structure[1])\n",
    "            else:\n",
    "                memory = sys.getsizeof(structure)\n",
    "            \n",
    "            memory_per_item = memory / data_size\n",
    "            print(f\"{name}: {memory} bytes total ({memory_per_item:.1f} per item)\")\n",
    "\n",
    "compare_memory_usage()\n",
    "```\n",
    "\n",
    "#### 3. When Worst-Case Performance Guarantees Are Critical\n",
    "Hash tables have O(n) worst-case performance due to collisions:\n",
    "\n",
    "```python\n",
    "def demonstrate_worst_case_scenario():\n",
    "    \"\"\"Show hash table worst-case behavior\"\"\"\n",
    "    \n",
    "    class PoorHashTable:\n",
    "        \"\"\"Hash table with deliberately poor hash function\"\"\"\n",
    "        \n",
    "        def __init__(self, size=10):\n",
    "            self.table = [[] for _ in range(size)]\n",
    "            self.size = size\n",
    "        \n",
    "        def _poor_hash(self, key):\n",
    "            # Deliberately poor: everything hashes to same bucket\n",
    "            return 0\n",
    "        \n",
    "        def put(self, key, value):\n",
    "            bucket = self.table[self._poor_hash(key)]\n",
    "            bucket.append((key, value))\n",
    "        \n",
    "        def get(self, key):\n",
    "            bucket = self.table[self._poor_hash(key)]\n",
    "            for k, v in bucket:  # Linear search - O(n)\n",
    "                if k == key:\n",
    "                    return v\n",
    "            return None\n",
    "    \n",
    "    # Compare with balanced binary search tree\n",
    "    class SimpleBST:\n",
    "        def __init__(self):\n",
    "            self.root = None\n",
    "        \n",
    "        def put(self, key, value):\n",
    "            self.root = self._put_recursive(self.root, key, value)\n",
    "        \n",
    "        def _put_recursive(self, node, key, value):\n",
    "            if not node:\n",
    "                return type('Node', (), {'key': key, 'value': value, 'left': None, 'right': None})()\n",
    "            \n",
    "            if key < node.key:\n",
    "                node.left = self._put_recursive(node.left, key, value)\n",
    "            elif key > node.key:\n",
    "                node.right = self._put_recursive(node.right, key, value)\n",
    "            else:\n",
    "                node.value = value\n",
    "            return node\n",
    "        \n",
    "        def get(self, key):\n",
    "            return self._get_recursive(self.root, key)\n",
    "        \n",
    "        def _get_recursive(self, node, key):\n",
    "            if not node:\n",
    "                return None\n",
    "            if key == node.key:\n",
    "                return node.value\n",
    "            elif key < node.key:\n",
    "                return self._get_recursive(node.left, key)\n",
    "            else:\n",
    "                return self._get_recursive(node.right, key)\n",
    "    \n",
    "    print(\"\\n=== Worst-Case Performance Comparison ===\")\n",
    "    \n",
    "    # Setup data\n",
    "    keys = list(range(100))\n",
    "    \n",
    "    # Poor hash table (all collisions)\n",
    "    poor_hash = PoorHashTable()\n",
    "    for key in keys:\n",
    "        poor_hash.put(key, f\"value_{key}\")\n",
    "    \n",
    "    # BST (guaranteed O(log n) for balanced trees)\n",
    "    bst = SimpleBST()\n",
    "    for key in keys:\n",
    "        bst.put(key, f\"value_{key}\")\n",
    "    \n",
    "    # Time lookups\n",
    "    search_keys = [25, 50, 75, 99]\n",
    "    \n",
    "    for key in search_keys:\n",
    "        # Poor hash table timing\n",
    "        start = time.time()\n",
    "        poor_hash.get(key)\n",
    "        poor_time = time.time() - start\n",
    "        \n",
    "        # BST timing\n",
    "        start = time.time()\n",
    "        bst.get(key)\n",
    "        bst_time = time.time() - start\n",
    "        \n",
    "        print(f\"Key {key}: Poor Hash={poor_time:.6f}s, BST={bst_time:.6f}s\")\n",
    "\n",
    "demonstrate_worst_case_scenario()\n",
    "```\n",
    "\n",
    "### Decision Framework\n",
    "\n",
    "Use this framework to decide when to use hash tables:\n",
    "\n",
    "#### Choose Hash Tables When:\n",
    "- ✅ **Fast average-case lookups** are critical\n",
    "- ✅ **Key-based access** is primary usage pattern  \n",
    "- ✅ **Order doesn't matter** for your use case\n",
    "- ✅ **Memory overhead is acceptable**\n",
    "- ✅ **Load factor can be controlled**\n",
    "\n",
    "#### Consider Alternatives When:\n",
    "- ❌ **Sorted order** must be maintained\n",
    "- ❌ **Range queries** are frequently needed\n",
    "- ❌ **Memory usage** must be minimized\n",
    "- ❌ **Worst-case performance** guarantees are critical\n",
    "- ❌ **Cache locality** is extremely important\n",
    "\n",
    "### Optimization Guidelines\n",
    "\n",
    "```python\n",
    "class OptimizedHashTableUsage:\n",
    "    \"\"\"Best practices for hash table usage\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Start with appropriate size to minimize resizing\n",
    "        self.data = {}\n",
    "        self.access_count = 0\n",
    "        self.resize_count = 0\n",
    "    \n",
    "    def choose_initial_size(self, expected_elements):\n",
    "        \"\"\"Choose initial size based on expected load\"\"\"\n",
    "        target_load_factor = 0.75\n",
    "        return int(expected_elements / target_load_factor)\n",
    "    \n",
    "    def batch_insert(self, items):\n",
    "        \"\"\"Batch insertions for better performance\"\"\"\n",
    "        # Pre-allocate if we know the size\n",
    "        if len(items) > len(self.data) * 2:\n",
    "            # Consider pre-sizing dictionary\n",
    "            pass\n",
    "        \n",
    "        for key, value in items:\n",
    "            self.data[key] = value\n",
    "    \n",
    "    def efficient_membership_testing(self, keys_to_check):\n",
    "        \"\"\"Efficient way to check multiple keys\"\"\"\n",
    "        # Use set intersection for multiple membership tests\n",
    "        existing_keys = set(self.data.keys())\n",
    "        found_keys = set(keys_to_check) & existing_keys\n",
    "        return found_keys\n",
    "    \n",
    "    def memory_efficient_counting(self, items):\n",
    "        \"\"\"Use defaultdict for counting to avoid key checks\"\"\"\n",
    "        from collections import defaultdict\n",
    "        counter = defaultdict(int)\n",
    "        \n",
    "        for item in items:\n",
    "            counter[item] += 1  # No need to check if key exists\n",
    "        \n",
    "        return dict(counter)\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n=== Optimization Examples ===\")\n",
    "optimizer = OptimizedHashTableUsage()\n",
    "\n",
    "# Efficient membership testing\n",
    "test_keys = ['a', 'b', 'c', 'd', 'e']\n",
    "optimizer.data = {'a': 1, 'c': 3, 'e': 5}\n",
    "found = optimizer.efficient_membership_testing(test_keys)\n",
    "print(f\"Found keys: {found}\")\n",
    "\n",
    "# Efficient counting\n",
    "items = ['apple', 'banana', 'apple', 'cherry', 'banana', 'apple']\n",
    "counts = optimizer.memory_efficient_counting(items)\n",
    "print(f\"Item counts: {counts}\")\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "Hash tables are powerful tools that excel in specific scenarios but aren't universal solutions. The key is understanding your access patterns, performance requirements, and constraints to make informed decisions about when they're the right choice for your particular problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fbdf01",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "### Primary Learning Materials\n",
    "1. [Data Structures and Algorithms Roadmap](https://roadmap.sh/datastructures-and-algorithms) - Hash Tables section\n",
    "2. [Hash Table Data Structure - GeeksforGeeks](https://www.geeksforgeeks.org/dsa/hash-table-data-structure/)\n",
    "3. [LeetCode Hash Table Problems](https://leetcode.com/tag/hash-table/)\n",
    "\n",
    "### Books and Textbooks\n",
    "\n",
    "#### Fundamental Texts\n",
    "- **\"Introduction to Algorithms\" by Cormen, Leiserson, Rivest, and Stein (CLRS)**\n",
    "  - Chapter 11: Hash Tables\n",
    "  - Comprehensive coverage of hash functions, collision resolution, and theoretical analysis\n",
    "\n",
    "- **\"Algorithms\" by Robert Sedgewick and Kevin Wayne**\n",
    "  - Chapter 3.4: Hash Tables\n",
    "  - Practical implementation details and performance analysis\n",
    "\n",
    "- **\"Data Structures and Algorithms in Python\" by Michael T. Goodrich**\n",
    "  - Chapter 10: Maps, Hash Tables, and Skip Lists\n",
    "  - Python-specific implementations and examples\n",
    "\n",
    "#### Advanced Topics\n",
    "- **\"The Art of Computer Programming, Volume 3\" by Donald Knuth**\n",
    "  - Section 6.4: Hashing\n",
    "  - Deep mathematical analysis of hash functions and collision resolution\n",
    "\n",
    "- **\"Algorithms and Data Structures\" by Niklaus Wirth**\n",
    "  - Classic treatment of hash table design principles\n",
    "\n",
    "### Online Resources\n",
    "\n",
    "#### Documentation and Tutorials\n",
    "- **Python Official Documentation**\n",
    "  - [`dict` objects](https://docs.python.org/3/library/stdtypes.html#dict)\n",
    "  - [`collections` module](https://docs.python.org/3/library/collections.html)\n",
    "\n",
    "- **Java Documentation**\n",
    "  - [`HashMap` class](https://docs.oracle.com/javase/8/docs/api/java/util/HashMap.html)\n",
    "  - [`HashSet` class](https://docs.oracle.com/javase/8/docs/api/java/util/HashSet.html)\n",
    "\n",
    "#### Interactive Learning\n",
    "- **VisuAlgo - Hash Table Visualization**\n",
    "  - https://visualgo.net/en/hashtable\n",
    "  - Interactive animations of hash table operations\n",
    "\n",
    "- **Algorithm Visualizer**\n",
    "  - https://algorithm-visualizer.org/\n",
    "  - Step-by-step hash table algorithm visualization\n",
    "\n",
    "### Research Papers and Academic Resources\n",
    "\n",
    "#### Foundational Papers\n",
    "- **\"Linear Probing and Graphs\" by L. J. Guibas and E. Szemerédi (1978)**\n",
    "  - Mathematical analysis of linear probing performance\n",
    "\n",
    "- **\"Robin Hood Hashing\" by Pedro Celis (1986)**\n",
    "  - Introduction of Robin Hood hashing technique\n",
    "\n",
    "- **\"Cuckoo Hashing\" by Rasmus Pagh and Flemming Friche Rodler (2001)**\n",
    "  - Worst-case O(1) lookup time guarantees\n",
    "\n",
    "#### Modern Developments\n",
    "- **\"HopScotch Hashing\" by Maurice Herlihy, Nir Shavit, and Moran Tzafrir (2008)**\n",
    "  - Lock-free hash table for concurrent environments\n",
    "\n",
    "- **\"Consistent Hashing and Random Trees\" by David Karger et al. (1997)**\n",
    "  - Distributed hash table design for load balancing\n",
    "\n",
    "### Practical Implementation Examples\n",
    "\n",
    "#### Language-Specific Resources\n",
    "\n",
    "**Python**\n",
    "```python\n",
    "# Built-in hash table implementations to study\n",
    "print(\"Python hash table implementations:\")\n",
    "print(\"- dict: General-purpose hash table\")\n",
    "print(\"- set: Hash table for unique elements\")\n",
    "print(\"- collections.defaultdict: Dict with default values\")\n",
    "print(\"- collections.Counter: Hash table for counting\")\n",
    "print(\"- collections.OrderedDict: Hash table maintaining insertion order\")\n",
    "\n",
    "# Example: Studying Python's dict implementation\n",
    "import sys\n",
    "d = {'a': 1, 'b': 2, 'c': 3}\n",
    "print(f\"\\nPython dict internals:\")\n",
    "print(f\"Size in memory: {sys.getsizeof(d)} bytes\")\n",
    "print(f\"Hash of 'a': {hash('a')}\")\n",
    "```\n",
    "\n",
    "**JavaScript**\n",
    "```javascript\n",
    "// JavaScript Map and Set (ES6+)\n",
    "const map = new Map([['key1', 'value1'], ['key2', 'value2']]);\n",
    "const set = new Set([1, 2, 3, 4]);\n",
    "\n",
    "// Object as hash table (traditional approach)\n",
    "const obj = { key1: 'value1', key2: 'value2' };\n",
    "```\n",
    "\n",
    "**Java**\n",
    "```java\n",
    "// Java HashMap and HashSet\n",
    "HashMap<String, Integer> map = new HashMap<>();\n",
    "HashSet<Integer> set = new HashSet<>();\n",
    "\n",
    "// ConcurrentHashMap for thread-safe operations\n",
    "ConcurrentHashMap<String, Integer> concurrentMap = new ConcurrentHashMap<>();\n",
    "```\n",
    "\n",
    "### Open Source Implementations to Study\n",
    "\n",
    "#### High-Performance Hash Tables\n",
    "- **Google's Swiss Table** (used in Abseil C++)\n",
    "  - https://github.com/abseil/abseil-cpp\n",
    "  - State-of-the-art hash table implementation\n",
    "\n",
    "- **Facebook's F14** (used in Folly C++)\n",
    "  - https://github.com/facebook/folly\n",
    "  - SIMD-optimized hash table\n",
    "\n",
    "- **Rust's HashMap**\n",
    "  - https://github.com/rust-lang/rust\n",
    "  - Memory-safe hash table implementation\n",
    "\n",
    "#### Educational Implementations\n",
    "- **Princeton Algorithms Course**\n",
    "  - https://algs4.cs.princeton.edu/34hash/\n",
    "  - Clean, educational implementations\n",
    "\n",
    "### Benchmarking and Performance Analysis\n",
    "\n",
    "#### Tools for Performance Testing\n",
    "```python\n",
    "import timeit\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def benchmark_hash_table_operations():\n",
    "    \"\"\"Benchmark different hash table operations\"\"\"\n",
    "    \n",
    "    sizes = [100, 1000, 10000, 100000]\n",
    "    operations = ['insert', 'lookup', 'delete']\n",
    "    results = {op: [] for op in operations}\n",
    "    \n",
    "    for size in sizes:\n",
    "        # Generate test data\n",
    "        keys = list(range(size))\n",
    "        random.shuffle(keys)\n",
    "        \n",
    "        # Insert benchmark\n",
    "        test_dict = {}\n",
    "        insert_time = timeit.timeit(\n",
    "            lambda: [test_dict.update({k: f\"value_{k}\"}) for k in keys[:1000]],\n",
    "            number=1\n",
    "        )\n",
    "        results['insert'].append(insert_time)\n",
    "        \n",
    "        # Lookup benchmark\n",
    "        lookup_keys = random.sample(keys, min(1000, len(keys)))\n",
    "        lookup_time = timeit.timeit(\n",
    "            lambda: [test_dict.get(k) for k in lookup_keys],\n",
    "            number=10\n",
    "        ) / 10\n",
    "        results['lookup'].append(lookup_time)\n",
    "        \n",
    "        # Delete benchmark\n",
    "        delete_keys = random.sample(list(test_dict.keys()), min(100, len(test_dict)))\n",
    "        delete_time = timeit.timeit(\n",
    "            lambda: [test_dict.pop(k, None) for k in delete_keys],\n",
    "            number=1\n",
    "        )\n",
    "        results['delete'].append(delete_time)\n",
    "    \n",
    "    return sizes, results\n",
    "\n",
    "# Run benchmark\n",
    "print(\"\\n=== Hash Table Performance Benchmark ===\")\n",
    "sizes, results = benchmark_hash_table_operations()\n",
    "\n",
    "for operation, times in results.items():\n",
    "    print(f\"\\n{operation.capitalize()} times:\")\n",
    "    for size, time_taken in zip(sizes, times):\n",
    "        print(f\"  Size {size}: {time_taken:.6f} seconds\")\n",
    "```\n",
    "\n",
    "### Interview Preparation Resources\n",
    "\n",
    "#### Practice Problems\n",
    "- **LeetCode Hash Table Problems**\n",
    "  - https://leetcode.com/tag/hash-table/\n",
    "  - Curated collection of hash table problems\n",
    "\n",
    "- **HackerRank Data Structures**\n",
    "  - https://www.hackerrank.com/domains/data-structures\n",
    "  - Hash table challenges with automated testing\n",
    "\n",
    "#### Common Interview Questions\n",
    "```python\n",
    "def common_interview_patterns():\n",
    "    \"\"\"Summary of common hash table interview patterns\"\"\"\n",
    "    \n",
    "    patterns = {\n",
    "        \"Two Pointers with Hash\": [\n",
    "            \"Two Sum\", \"Three Sum\", \"Four Sum\",\n",
    "            \"Subarray Sum Equals K\"\n",
    "        ],\n",
    "        \n",
    "        \"Sliding Window with Hash\": [\n",
    "            \"Longest Substring Without Repeating Characters\",\n",
    "            \"Minimum Window Substring\",\n",
    "            \"Find All Anagrams in a String\"\n",
    "        ],\n",
    "        \n",
    "        \"Frequency Counting\": [\n",
    "            \"Top K Frequent Elements\",\n",
    "            \"Group Anagrams\",\n",
    "            \"Word Pattern\"\n",
    "        ],\n",
    "        \n",
    "        \"Design Problems\": [\n",
    "            \"LRU Cache\",\n",
    "            \"Design HashSet\",\n",
    "            \"Design HashMap\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"Common Hash Table Interview Patterns:\")\n",
    "    for pattern, problems in patterns.items():\n",
    "        print(f\"\\n{pattern}:\")\n",
    "        for problem in problems:\n",
    "            print(f\"  - {problem}\")\n",
    "\n",
    "common_interview_patterns()\n",
    "```\n",
    "\n",
    "### Advanced Topics for Further Study\n",
    "\n",
    "#### Distributed Hash Tables\n",
    "- **Consistent Hashing**: For distributed systems\n",
    "- **Chord Protocol**: Peer-to-peer distributed hash table\n",
    "- **Kademlia**: DHT used in BitTorrent\n",
    "\n",
    "#### Specialized Hash Tables\n",
    "- **Bloom Filters**: Probabilistic membership testing\n",
    "- **Count-Min Sketch**: Frequency estimation in streams\n",
    "- **HyperLogLog**: Cardinality estimation\n",
    "\n",
    "#### Concurrent Hash Tables\n",
    "- **Lock-free hash tables**: Using atomic operations\n",
    "- **Read-Copy-Update (RCU)**: For read-heavy workloads\n",
    "- **Hazard pointers**: Memory management in lock-free structures\n",
    "\n",
    "### Tools and Libraries\n",
    "\n",
    "#### Profiling and Analysis\n",
    "```python\n",
    "# Memory profiling\n",
    "import tracemalloc\n",
    "import psutil\n",
    "\n",
    "def profile_hash_table_memory():\n",
    "    \"\"\"Profile memory usage of hash table operations\"\"\"\n",
    "    \n",
    "    tracemalloc.start()\n",
    "    \n",
    "    # Create large hash table\n",
    "    data = {i: f\"value_{i}\" for i in range(10000)}\n",
    "    \n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    print(f\"Current memory usage: {current / 1024 / 1024:.1f} MB\")\n",
    "    print(f\"Peak memory usage: {peak / 1024 / 1024:.1f} MB\")\n",
    "    \n",
    "    tracemalloc.stop()\n",
    "\n",
    "# Performance profiling with cProfile\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "def profile_hash_operations():\n",
    "    \"\"\"Profile hash table operations performance\"\"\"\n",
    "    \n",
    "    def hash_operations():\n",
    "        data = {}\n",
    "        for i in range(10000):\n",
    "            data[i] = i * 2\n",
    "        \n",
    "        for i in range(5000):\n",
    "            _ = data[i]\n",
    "        \n",
    "        for i in range(1000):\n",
    "            del data[i]\n",
    "    \n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    hash_operations()\n",
    "    profiler.disable()\n",
    "    \n",
    "    stats = pstats.Stats(profiler)\n",
    "    stats.sort_stats('cumulative')\n",
    "    stats.print_stats(10)\n",
    "\n",
    "print(\"\\n=== Memory Profiling ===\")\n",
    "profile_hash_table_memory()\n",
    "```\n",
    "\n",
    "### Contributing to Open Source\n",
    "\n",
    "If you want to deepen your understanding by contributing:\n",
    "\n",
    "- **Python**: Contribute to CPython's dict implementation\n",
    "- **Rust**: Work on HashMap optimizations\n",
    "- **C++**: Contribute to standard library implementations\n",
    "- **Educational**: Create visualizations or tutorials\n",
    "\n",
    "### Next Steps in Learning Path\n",
    "1. ✅ **Arrays** (Previous)\n",
    "2. ✅ **Linked Lists** (Previous)\n",
    "3. ✅ **Stacks and Queues** (Previous)\n",
    "4. ✅ **Hash Tables** (Current)\n",
    "\n",
    "### Summary\n",
    "\n",
    "This comprehensive resource list provides multiple pathways for deepening your understanding of hash tables, from theoretical foundations to practical implementations and advanced optimizations. Choose resources based on your current level and specific interests in the field."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
